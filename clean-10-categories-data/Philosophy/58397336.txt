[[File:Michael Polanyi.png|thumb|Professor Michael Polanyi on a hike in England]]
'''Polanyi's paradox''', named in honour of the British-Hungarian philosopher [[Michael Polanyi]], is the theory that human knowledge of how the world functions and capability are, to a large extent, beyond our explicit understanding. The theory was articulated by Michael Polanyi in his book ''The Tacit Dimension'' in 1966, but it was economist [[David Autor]] that named it as Polanyi's paradox in his 2014 research paper on “Polanyi's Paradox and the Shape of Employment Growth”.<ref name=":0">{{Citation|last=Autor|first=David|title=Polanyi's Paradox and the Shape of Employment Growth|url=http://www.nber.org.ezproxy1.library.usyd.edu.au/papers/w20485.pdf|pages=1–48|year=2014|series=NBER Working Paper Series|place=Cambridge, MA|publisher=National Bureau of Economic Research}}</ref>

Summarised in the slogan "We can know more than we can tell", Polanyi's paradox is mainly to explain the cognitive phenomenon that there exist many tasks which we, human beings, understand intuitively how to perform but cannot verbalize the rules or procedures behind it.<ref name=":1" /> 

This "self-ignorance" is common to many human activities, from driving a car in traffic to face recognition.<ref name=":5" /> As Polanyi argues, humans are relying on their [[tacit knowledge]], which is difficult to adequately express by verbal means, when engaging these tasks.<ref name=":1">{{Cite book|title=The Tacit Dimension|last=Polanyi|first=Michael|publisher=University of Chicago Press|year=May 2009|isbn=9780226672984|location=Chicago|pages=1–26|oclc=262429494}}</ref> Polanyi's paradox has been widely considered a major obstacle in the fields of AI and automation, since the absence of consciously accessible knowledge creates tremendous difficulty in programming.<ref name=":6" />

== Origins ==
British-Hungarian philosopher Michael Polanyi regularly studied the causes behind human ability to acquire knowledge that they cannot explain through logical deduction. In his work ''The Tacit Dimension'' (1966)'','' Polanyi explored the 'tacit' dimension to human knowledge and developed the concept of "tacit knowledge", as opposed to the term "[[explicit knowledge]]".<ref name=":1" />

[[Tacit knowledge]] can be defined as knowledge people learn from experiences and internalize unconsciously, which is therefore difficult to articulate and codify it in a tangible form. Explicit knowledge, the opposite of tacit knowledge, is knowledge that can be readily verbalized and formalized.<ref name=":1" /> Tacit knowledge is largely acquired through [[implicit learning]], the process by which information is learned independently of the subjects' awareness. For example, native speakers tacitly acquire their language in early childhood without consciously studying specific grammar rules (explicit knowledge), but with extensive exposure to day-to-day communication.<ref>{{Cite journal|last=Reber|first=Arthur|date=September 1989|title=Implicit Learning and Tacit Knowledge|url=https://www.researchgate.net/publication/232481584|journal=Journal of Experimental Psychology: General|volume=118|issue=3|pages=219–235|doi=10.1037/0096-3445.118.3.219|citeseerx=10.1.1.207.6707}}</ref> Besides, people can only limitedly transfer their tacit knowledge through close interactions (sharing experiences with one another or observing others' behaviors). A certain level of trust needs to be established between individuals to capture tacit knowledge.<ref name=":10">{{Cite book|title=Ganga Rejuvenation : Governance Challenges and Policy Options|last=Asanarong|first=Thanathorn|last2=Jeon|first2=Sowon|last3=Ren|first3=Yuanlin|last4=Yeo|first4=Christopher|date=18 December 2018|publisher=World Scientific|others=Wu Xun, Robert James Wasson, Ora-Orn Poocharoen|isbn=9789814704588|location=New Jersey|pages=349|chapter=Creating a Knowledge Management Culture for Ganga River|oclc=1013819475}}</ref>

Tacit knowledge comprises a range of conceptual and sensory information that is featured with strong personal subjectivity. It is implicitly reflected in human actions; as argued by Polanyi, "tacit knowledge dwells in our awareness".<ref name=":1" /> People's skills, experiences, insight, creativity and judgement all fall into this dimension.<ref name=":2">{{Citation|last=Chugh|first=Ritesh|title=Do Australian Universities Encourage Tacit Knowledge Transfer|url=https://www.academia.edu/19661139|journal=Proceedings of the 7th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management|pages=128–135|year=2015|place=Lisbon, PT}}</ref> Tacit knowledge can also be described as ''know-how,'' distinguishing from ''know-that'' or ''facts.''<ref name=":10" /> Before Polanyi, Gilbert Ryle published a paper in 1945 drawing the distinction between ''knowing-that (knowledge of proposition)'' and ''knowing-how.'' According to Ryle, this ''know-how'' knowledge is the instinctive and intrinsic knowledge ingrained in the individual's human capability.<ref>{{Cite journal|last=Ryle|first=Gilbert|date=1945|title=Knowing How and Knowing That: The Presidential Address|journal=Proceedings of the Aristotelian Society|volume=46|pages=1–16|jstor=4544405|doi=10.1093/aristotelian/46.1.1}}</ref>

Since tacit knowledge cannot be stated in propositional or formal form, Polanyi concludes such inability in articulation in the slogan ‘We can know more than we can tell’.<ref name=":1" /> Daily activities based on tacit knowledge include recognizing a face, driving a car, riding a bike, writing a persuasive paragraph, developing a hypothesis to explain a poorly understood phenomenon.<ref name=":2" /> Take facial recognition as an illustration: we can recognize our acquaintance's face out of a million others while we are not conscious about the knowledge of his face. It would be difficult for us to describe the precise arrangement of his eyes, nose and mouth, since we memorize the face unconsciously.<ref name=":6" />

As a prelude to ''The Tacit Dimension'', in his book ''Personal Knowledge'' (1958), Polanyi claims that all knowing is personal, emphasizing the profound effects of personal feelings and commitments on the practice of science and knowledge. Arguing against the then dominant Empiricists view that minds and experiences are reducible to sense data and collections of rules, he advocates a [[Postpositivism|post-positivist]] approach that recognizes human knowledge is often beyond their explicit expression. Any attempt to specify tacit knowing only leads to self-evident axioms that cannot tell us why we should accept them.<ref>{{Cite book|title=Personal Knowledge : Towards a Post-critical Philosophy|last=Polanyi|first=Michael|publisher=University Of Chicago Press|year=1974|isbn=978-0226672885|location=Chicago|oclc=880960082}}</ref>

== Implications ==
Polanyi's observation has deep implications in the AI field since the paradox he identified that "our tacit knowledge of how the world works often exceeds our explicit understanding" accounts for many of the challenges for computerization and automation over the past five decades.<ref name=":0" /> Automation requires high levels of exactness to inform the computer what is supposed to be done while tacit knowledge cannot be conveyed in a propositional form. Therefore, machines cannot provide successful outcomes in many cases: they have explicit knowledge (raw data) but nevertheless, do not know how to use such knowledge to understand the task as whole.<ref name=":10" /> This discrepancy between human reasoning and AI learning algorithms makes it difficult to automate tasks that demand common sense, flexibility, adaptability and judgment — human intuitive knowledge.<ref name=":6">{{Cite book|title=Android Dreams: the Past, Present and Future of Artificial Intelligence|last=Walsh|first=Toby|publisher=C Hurst & Co Publishers Ltd|date=September 7, 2017|isbn=9781849048712|location=London|pages=89–97|oclc=985805795}}</ref>

MIT economist David Autor is one of the leading sceptics who doubt the prospects for machine intelligence. Despite the exponential growth in computational resources and the relentless pace of automation since the 1990s, Autor argues, Polanyi's paradox impedes modern algorithms to replace human labor in a range of skilled jobs. The extent of machine substitution of human labor, therefore, has been overestimated by journalists and expert commentators.<ref name=":0" /> Although contemporary computer science strives for prevailing over Polanyi's paradox, the ever-changing, unstructured nature of some activities currently presents intimidating challenges for automation. Despite years of time and billions of investment spent on the development of [[self-driving car]]s and cleaning robots, these machine learning systems continue to struggle with their low adaptability and interpretability, from self-driving cars' inability to make an unexpected detour to cleaning robots' vulnerability to unmonitored pets or kids.<ref>{{Cite book|title=Humans as a Service : the Promise and Perils of Work in the Gig Economy|last=Prassl|first=Jeremias|publisher=Oxford University Press|year=2018|isbn=9780198797012|location=Oxford|pages=138–139|oclc=1005117556}}</ref> Instead, to let self-driving cars function optimally, we have to change current road infrastructure significantly, minimizing the need for human capabilities in the whole driving process.<ref>{{Cite web|url=https://www.washingtonpost.com/news/wonk/wp/2015/01/15/5-confounding-questions-that-hold-the-key-to-the-future-of-driverless-cars/|title=5 Confounding Questions that Hold the Key to the Future of Driverless Cars|last=Badger|first=Emily|date=January 15, 2015|website=Washington Post|language=en|access-date=2018-10-31|archive-url=https://web.archive.org/web/20180825074159/https://www.washingtonpost.com/news/wonk/wp/2015/01/15/5-confounding-questions-that-hold-the-key-to-the-future-of-driverless-cars/|archive-date=August 25, 2018|url-status=live}}</ref>

The increasing [[Job polarisation|occupational polarisation]] in the past few decades —the growth of both high-paid, high-skill abstract jobs and lower-paid, low-skill manual jobs — has been a manifestation of Polanyi's paradox. According to Autor, there are two types of tasks proven stubbornly challenging for artificial intelligence (AI): abstract tasks that require problem-solving capabilities, intuition, creativity and persuasion on the one hand, and manual tasks demanding situational adaptability, visual recognition, language understanding, and in-person interactions on the other. Abstract tasks are characteristic of professional, managerial, and technical occupations, while service and laborer occupations involve many manual tasks (e.g. cleaning, lifting and throwing). These jobs tend to be complemented by machines rather than substituted.<ref name=":0" />

By contrast, as the price of computing power declines, computers extensively substitute for routine tasks that can be codified into clear sets of instructions, resulting in a dramatical decline in employment of routine task-&shy;intensive jobs.<ref name=":0" /> This polarization has resulted in a shrinking middle class across industrialized economies since many middle-income occupations in sales, office and administrative work and repetitive production work are task-&shy;intensive. Moreover, the subsequent growth in income inequality and wealth disparity has recently emerged as a major socio-economic issue in developed countries.<ref>{{Cite journal|last=Vardi|first=Moshe|date=February 2015|title=Is Information Technology Destroying the Middle Class?|url=https://cacm.acm.org/magazines/2015/2/182648-is-information-technology-destroying-the-middle-class/fulltext|journal=Communications of the ACM|volume=58|issue=2|pages=5|doi=10.1145/2666241|doi-access=free|access-date=2018-10-16|archive-url=https://web.archive.org/web/20170205042620/http://cacm.acm.org/magazines/2015/2/182648-is-information-technology-destroying-the-middle-class/fulltext/|archive-date=2017-02-05|url-status=live}}</ref>

== Criticism ==
Some technological optimists argue that recent advances in [[machine learning]] have overcome Polanyi's paradox. Instead of relying on programmer’s algorithms to instruct them in human knowledge, computer systems are now able to learn tacit rules from context, abundant data, and applied statistics on their own. Since machines can infer the tacit knowledge that human beings draw upon from examples without human assistance, they are no longer limited by those rules tacitly applied but not explicitly understood by humans.<ref name=":3">{{Citation|last=Susskind|first=Daniel|title=Re-Thinking the Capabilities of Machines in Economics|url=https://www.economics.ox.ac.uk/materials/papers/15127/825-susskind-capabilities-of-machines.pdf|pages=1–14|year=2017|series=University of Oxford Department of Economics Discussion Paper Series|place=Oxford, OX|access-date=2018-10-04|archive-url=https://web.archive.org/web/20170626123455/https://www.economics.ox.ac.uk/materials/papers/15127/825-susskind-capabilities-of-machines.pdf|archive-date=2017-06-26|url-status=live}}</ref>
[[File:Lee Sedol (B) vs AlphaGo (W) - Game 1.jpg|thumb|Lee Sedol (B) vs AlphaGo (W) - Game 1]]
[[AlphaGo]] program built by the Google subsidiary [[DeepMind]] is a great example of how advances in AI have allowed mindless machines to perform tasks based on tacit knowledge outstandingly. In the 2016 tournament of the strategy game Go, DeepMind's AlphaGo program successfully defeated one of the world's top GO players, [[Lee Sedol|Lee Se-dol]], four games to one. DeepMind team employed an approach known as [[deep learning]] to build human-type judgment into AI systems; therefore, they can figure out complex winning strategies by seeing vast examples of Go matches.<ref name=":5">{{Cite news|url=https://www.nytimes.com/2016/03/16/opinion/where-computers-defeat-humans-and-where-they-cant.html|title=Where Computers Defeat Humans, and Where They Can’t|last=McAfee|first=Andrew|date=16 March 2016|work=The New York Times|access-date=2018-10-04|last2=Brynjolfsson|first2=Erik|archive-url=https://web.archive.org/web/20181016130000/https://www.nytimes.com/2016/03/16/opinion/where-computers-defeat-humans-and-where-they-cant.html|archive-date=16 October 2018|url-status=live}}</ref>

On the other hand, as Carr argues, the assumption that computers need to be able to reproduce tacit knowledge applied by humans to perform complicated tasks is essentially doubtable. When performing demanding tasks, it is not necessary for systems and machines to reflect the rules that human beings follow at all. The requirement is to replicate our outcomes for practical purposes, rather than our means.<ref>{{Cite book|title=The Glass Cage: Automation and Us|last=Carr|first=Nicholas|publisher=W. W. Norton & Company|date=September 29, 2014|isbn=9780393240764|edition=  First|location=New York|pages=11–12|oclc=870098283}}</ref>

[[Jerry Kaplan]], a Silicon Valley entrepreneur and AI expert, also illustrates this point in his book ''Humans Need Not Apply'' by discussing four resources and capabilities required to accomplish any given task: awareness, energy, reasoning and means. Humans' biological system (the brain-body complex) naturally integrates all these four properties, while in the electronic domain machines nowadays are given these abilities by accelerating developments in robotics, machine learning, and perception powering systems. For example, sensory data provided by a wide network of sensors enable AI to perceive various aspects of the environment and respond instantly in chaotic and complex real-world situations (awareness); orders and signals for actuating devices can be centralised and managed in [[Computer cluster|server clusters]] or on the 'cloud' (reasoning).<ref name=":7">{{Cite book|title=Humans Need Not Apply : a Guide to Wealth and Work in the Age of Artificial Intelligence|last=Kaplan|first=Jerry|publisher=Yale University Press|date=August 4, 2015|isbn=9780300223576|location=New Haven|pages=41–43, 145|oclc=907143085}}</ref> Kaplan's argument directly supports the proposition that Polanyi's paradox can no longer impede further levels of automation, whether in performing routine jobs or manual jobs. As Kaplan puts it, "Automation is blind to the colour of your collar."<ref name=":7" />

One example confirms Kaplan's argument is the introduction of Cloud AutoML, an automated system that could help every business design AI software, by Google Brain AI research group in 2017. The learning algorithms of AutoML automates the process of building machine-learning models that can take on a particular task, aiming to democratize AI to the largest possible community of developers and businesses. According to Google’s CEO, Cloud AutoML has taken over some of the work of programmers (which is, in the words of Autor, "abstract task") and thereby offered one solution to the shortage in machine-learning experts.<ref>{{Cite news|url=https://www.technologyreview.com/s/607894/why-googles-ceo-is-excited-about-automating-artificial-intelligence/|title=Google’s CEO is excited about seeing AI take over some work of his AI experts|last=Simonite|first=Tom|date=May 17, 2017|work=MIT Technology Review|access-date=2018-10-30}}</ref>

== Related theories ==

=== Moravec's paradox ===

[[Moravec's paradox|Moravec’s paradox]] is very closed related to Polanyi's paradox, which claims that compared with sophisticated tasks demanding high-level reasoning, it is harder for computers to master low-level physical and cognitive skills that are natural and easy for humans to perform. Examples include [[natural language processing]] and dextrous physical movements (e.g. running over rough terrain).<ref name=":4">{{Cite book|title=The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies|last=Brynjolfsson|first=Erik|last2=McAfee|first2=Andrew|publisher=W. W. Norton & Company|date=January 20, 2014|isbn=9780393239355|edition=  First|location=New York|pages=47–50|oclc=867423744}}</ref>

Robotics experts have, accordingly, found it difficult to automate the skills of even the least-trained manual worker, since these jobs require perception and mobility (tacit knowledge).<ref name=":4" /> In the words of the cognitive scientist Steven Pinker from his book ''[[The Language Instinct]],'' "The main lesson of thirty-five years of AI research is that the hard problems are easy and the easy problems are hard."<ref name=":9">{{Cite book|title=The Language Instinct: How the Mind Creates Language|last=Pinker|first=Steven|publisher=William Morrow and Company|year=1994|isbn=978-0688121419|location=New York|oclc=28723210}}</ref>

Corresponding to David Autor's discussion on jobs polarization, Pinker maintains that the appearance of the new generation's intelligent machines would place stock analysts, petrochemical engineers and parole board members in danger of being replaced. Gardeners, receptionists, and cooks are, by contrast, currently secure.<ref name=":9" />

=== Plato's Problem ===

[[Plato's Problem]] is the term given by Noam Chomsky to "the problem of explaining how we can know so much" given our limited experience.

=== Poverty of the stimulus (POS) ===

[[Poverty of the stimulus|Poverty of the stimulus (POS)]] is the argument from linguistics that children are not exposed to rich enough data within their linguistic environments to acquire every feature of their language.

=== Meno’s Paradox ===

[[Meno|Meno’s Paradox]] can be formulated as follows:
# If you know what you’re looking for, inquiry is unnecessary.
# If you don’t know what you’re looking for, inquiry is impossible.
# Therefore, inquiry is either unnecessary or impossible.

There is within these arguments an implicit premise that either you know what you’re looking for or you don’t know what you’re looking for.

=== The Learning Paradox ===

The Learning Paradox (Fodor 1980) holds that knowledge can either not be new, or not be learned. If new knowledge can be expressed in terms of old knowledge, it is not new. If it cannot be expressed in terms of old knowledge, it cannot be understood. Therefore, learning something genuinely novel is impossible and all essential structures must be present at birth.

== References ==
{{Reflist}}

{{DEFAULTSORT:Polanyi's paradox}}
[[Category:Philosophy]]
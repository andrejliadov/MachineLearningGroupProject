{{short description|Words whose letters are taken from an alphabet and are well-formed according to a specific set of rules}}
{{About|a technical term in mathematics and computer science|related studies about natural languages|Formal semantics (linguistics)| formal modes of speech in natural languages|Register (sociolinguistics)}}
{{Use dmy dates|date=July 2013}}
[[File:Syntax tree.svg|thumb|Structure of the syntactically well-formed, although nonsensical, English sentence, ''"Colorless green ideas sleep furiously"'' ([[Colorless green ideas sleep furiously|historical example]] from [[Noam Chomsky|Chomsky]] 1957).]]
In [[mathematics]], [[computer science]], and [[linguistics]], a '''formal language''' consists of [[string (computer science)|words]] whose [[symbol (formal)|letters]] are taken from an [[alphabet (computer science)|alphabet]] and are [[well-formedness|well-formed]] according to a specific set of rules.

The [[Alphabet (computer science)|alphabet]] of a formal language consist of symbols, letters, or tokens that concatenate into strings of the language.<ref>See e.g. {{citation|title=Formal Languages and Compilation|series=Texts in Computer Science|first=Stefano Crespi|last=Reghizzi|publisher=Springer|year=2009|isbn=9781848820500|page=8|quote=An alphabet is a finite set}}.</ref> Each string concatenated from symbols of this alphabet is called a word, and the words that belong to a particular formal language are sometimes called ''well-formed words'' or ''[[well-formed formula]]s''. A formal language is often defined by means of a [[formal grammar]] such as a [[regular grammar]] or [[context-free grammar]], which consists of its [[formation rule]]s.

The field of '''formal language theory''' studies primarily the purely [[syntax|syntactical]] aspects of such languages—that is, their internal structural patterns. Formal language theory sprang out of linguistics, as a way of understanding the syntactic regularities of [[natural language]]s.
In computer science, formal languages are used among others as the basis for defining the grammar of [[programming language]]s and formalized versions of subsets of natural languages in which the words of the language represent concepts that are associated with particular meanings or [[semantics]]. In [[computational complexity theory]], [[decision problem]]s are typically defined as formal languages, and [[complexity class]]es are defined as the sets of the formal languages that can be [[parser|parsed by machines]] with limited computational power. In [[logic]] and the [[foundations of mathematics]], formal languages are used to represent the syntax of [[axiomatic system]]s, and [[Formalism (mathematics)|mathematical formalism]] is the philosophy that all of mathematics can be reduced to the syntactic manipulation of formal languages in this way.

== History ==
{{Expand section|date=April 2011}}
The first formal language is thought to be the one used by [[Gottlob Frege]] in his ''[[Begriffsschrift]]'' (1879), literally meaning "concept writing", and which Frege described as a "formal language of pure thought."<ref name="Herken1995">{{cite book|editor=Rolf Herken|title=The universal Turing machine: a half-century survey|chapter-url=https://books.google.com/books?id=YafIDVd1Z68C&pg=PA290|year=1995|publisher=Springer|isbn=978-3-211-82637-9|page=290|chapter=Influences of Mathematical Logic on Computer Science|author=Martin Davis}}</ref>

[[Axel Thue]]'s early [[semi-Thue system]], which can be used for rewriting strings, was influential on [[formal grammar]]s.

== Words over an alphabet ==
An '''alphabet''', in the context of formal languages, can be any [[set (mathematics)|set]], although it often makes sense to use an [[alphabet]] in the usual sense of the word, or more generally a [[character set]] such as [[ASCII]] or [[Unicode]].  The elements of an alphabet are called its '''letters'''.  An alphabet may contain an [[countable set|infinite]] number of elements;{{NoteTag|For example, [[first-order logic]] is often expressed using an alphabet that, besides symbols such as ∧, ¬, ∀ and parentheses, contains infinitely many elements ''x''<sub>0</sub>,&nbsp;''x''<sub>1</sub>,&nbsp;''x''<sub>2</sub>,&nbsp;… that play the role of variables.}} however, most definitions in formal language theory specify alphabets with a finite number of elements, and most results apply only to them.

A '''word''' over an alphabet can be any finite sequence (i.e., [[string (computer science)|string]]) of letters. The set of all words over an alphabet Σ is usually denoted by Σ<sup>*</sup> (using the [[Kleene star]]). The length of a word is the number of letters it is composed of. For any alphabet, there is only one word of length 0, the ''empty word'', which is often denoted by e, ε, λ or even Λ. By [[concatenation]] one can combine two words to form a new word, whose length is the sum of the lengths of the original words. The result of concatenating a word with the empty word is the original word.

In some applications, especially in [[logic]], the alphabet is also known as the ''vocabulary'' and words are known as ''formulas'' or ''sentences''; this breaks the letter/word metaphor and replaces it by a word/sentence metaphor.

==Definition==
A '''formal language''' ''L'' over an alphabet Σ is a [[subset]] of Σ<sup>*</sup>, that is, a set of [[#Words over an alphabet|words]] over that alphabet. Sometimes the sets of words are grouped into expressions, whereas rules and constraints may be formulated for the creation of 'well-formed expressions'.

In computer science and mathematics, which do not usually deal with [[natural language]]s, the adjective "formal" is often omitted as redundant.

While formal language theory usually concerns itself with formal languages that are described by some syntactical rules, the actual definition of the concept "formal language" is only as above: a (possibly infinite) set of finite-length strings composed from a given alphabet, no more and no less.  In practice, there are many languages that can be described by rules, such as [[regular language]]s or [[context-free language]]s.  The notion of a [[formal grammar]] may be closer to the intuitive concept of a "language," one described by syntactic rules. By an abuse of the definition, a particular formal language is often thought of as being equipped with a formal grammar that describes it.

==Examples==

The following rules describe a formal language&nbsp;{{mvar|L}} over the alphabet Σ&nbsp;=&nbsp;{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, +, =}:
* Every nonempty string that does not contain "+" or "=" and does not start with "0" is in&nbsp;{{mvar|L}}.
* The string "0" is in&nbsp;{{mvar|L}}.
* A string containing "=" is in&nbsp;{{mvar|L}} if and only if there is exactly one "=", and it separates two valid strings of&nbsp;{{mvar|L}}.
* A string containing "+" but not "=" is in&nbsp;{{mvar|L}} if and only if every "+" in the string separates two valid strings of&nbsp;{{mvar|L}}.
* No string is in&nbsp;{{mvar|L}} other than those implied by the previous rules.
Under these rules, the string "23+4=555" is in&nbsp;{{mvar|L}}, but the string "=234=+" is not. This formal language expresses [[natural number]]s, well-formed additions, and well-formed addition equalities, but it expresses only what they look like (their [[syntax]]), not what they mean ([[semantics]]). For instance, nowhere in these rules is there any indication that "0" means the number zero,   "+" means addition, "23+4=555" is false, etc.

=== Constructions ===<!-- [[empty language]] redirects here -->
For finite languages, one can explicitly enumerate all well-formed words. For example, we can describe a language&nbsp;{{mvar|L}} as just {{mvar|L}}&nbsp;=&nbsp;{a, b, ab, cba}. The [[degeneracy (mathematics)|degenerate]] case of this construction is the '''empty language''', which contains no words at all (<span class="nounderlines">{{mvar|L}}&nbsp;=&nbsp;[[∅]]</span>).

However, even over a finite (non-empty) alphabet such as Σ&nbsp;=&nbsp;{a,&nbsp;b} there are an infinite number of finite-length words that can potentially be expressed: "a", "abb", "ababba", "aaababbbbaab",&nbsp;.... Therefore, formal languages are typically infinite, and describing an infinite formal language is not as simple as writing ''L''&nbsp;=&nbsp;{a, b, ab, cba}. Here are some examples of formal languages:
* {{mvar|L}} = Σ<sup>*</sup>, the set of ''all'' words over Σ;
* {{mvar|L}} = {a}<sup>*</sup> = {a<sup>''n''</sup>}, where ''n'' ranges over the natural numbers and "a<sup>''n''</sup>" means "a" repeated ''n'' times (this is the set of words consisting only of the symbol "a");
* the set of syntactically correct programs in a given programming language (the syntax of which is usually defined by a [[context-free grammar]]);
* the set of inputs upon which a certain [[Turing machine]] halts; or
* the set of maximal strings of [[alphanumeric]] [[ASCII]] characters on this line, i.e.,<br> the set {the, set, of, maximal, strings, alphanumeric, ASCII, characters, on, this, line, i, e}.

== Language-specification formalisms ==

Formal languages are used as tools in multiple disciplines. However, formal language theory rarely concerns itself with particular languages (except as examples), but is mainly concerned with the study of various types of formalisms to describe languages. For instance, a language can be given as
* those strings generated by some [[formal grammar]];
* those strings described or matched by a particular [[regular expression]];
* those strings accepted by some [[Automata theory|automaton]], such as a [[Turing machine]] or [[Finite-state machine|finite-state automaton]];
* those strings for which some [[decision problem|decision procedure]] (an [[algorithm]] that asks a sequence of related YES/NO questions) produces the answer YES.

Typical questions asked about such formalisms include:

* What is their expressive power? (Can formalism ''X'' describe every language that formalism ''Y'' can describe? Can it describe other languages?)
* What is their recognizability? (How difficult is it to decide whether a given word belongs to a language described by formalism ''X''?)
* What is their comparability? (How difficult is it to decide whether two languages, one described in formalism ''X'' and one in formalism ''Y'', or in ''X'' again, are actually the same language?).

Surprisingly often, the answer to these decision problems is "it cannot be done at all", or "it is extremely expensive" (with a characterization of how expensive). Therefore, formal language theory is a major application area of [[Computability theory (computer science)|computability theory]] and [[computational complexity theory|complexity theory]]. Formal languages may be classified in the [[Chomsky hierarchy]] based on the expressive power of their generative grammar as well as the complexity of their recognizing [[automata theory|automaton]]. [[Context-free grammar]]s and [[regular grammar]]s provide a good compromise between expressivity and ease of [[parsing]], and are widely used in practical applications.

== Operations on languages ==

Certain operations on languages are common. This includes the standard set operations, such as union, intersection, and complement. Another class of operation is the element-wise application of string operations.

Examples: suppose <math>L_1</math> and <math>L_2</math> are languages over some common alphabet <math>\Sigma</math>.
* The ''[[concatenation]]'' <math>L_1 \cdot L_2</math> consists of all strings of the form <math>vw</math> where <math>v</math> is a string from <math>L_1</math> and <math>w</math> is a string from <math>L_2</math>.
* The ''intersection'' <math>L_1 \cap L_2</math> of <math>L_1</math> and <math>L_2</math> consists of all strings that are contained in both languages
* The ''complement'' <math>\neg L_1</math> of <math>L_1</math> with respect to <math>\Sigma</math> consists of all strings over <math>\Sigma</math> that are not in <math>L_1</math>.
* The [[Kleene star]]: the language consisting of all words that are concatenations of zero or more words in the original language;
* ''Reversal'':
** Let ''ε'' be the empty word, then <math>\varepsilon^R = \varepsilon</math>, and
** for each non-empty word <math>w = \sigma_1 \cdots \sigma_n</math> (where <math>\sigma_1, \ldots, \sigma_n</math>are elements of some alphabet), let <math>w^R = \sigma_n \cdots \sigma_1</math>,
** then for a formal language <math>L</math>, <math>L^R = \{ w^R \mid w \in L \}</math>.
* [[String homomorphism]]

Such [[string operations]] are used to investigate [[Closure (mathematics)|closure properties]] of classes of languages. A class of languages is closed under a particular operation when the operation, applied to languages in the class, always produces a language in the same class again. For instance, the [[context-free language]]s are known to be closed under union, concatenation, and intersection with [[regular language]]s, but not closed under intersection or complement. The theory of [[cone (formal languages)|trios]] and [[abstract family of languages|abstract families of languages]] studies the most common closure properties of language families in their own right.<ref>{{harvtxt|Hopcroft|Ullman|1979}}, Chapter 11: Closure properties of families of languages.</ref>

:{| class="wikitable"
|+ align="top"|Closure properties of language families (<math>L_1</math> Op <math>L_2</math> where both <math>L_1</math> and <math>L_2</math> are in the language family given by the column). After Hopcroft and Ullman.
|-
! Operation
!
! [[Regular language|Regular]]
! [[Deterministic context-free language|DCFL]]
! [[Context free language|CFL]]
! [[Indexed language|IND]]
! [[Context sensitive language|CSL]]
! [[Recursive language|recursive]]
! [[Recursively enumerable language|RE]]
|-
|[[Union (set theory)|Union]]
|<math>L_1 \cup L_2 = \{w \mid w \in L_1 \lor w \in L_2\} </math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|[[Intersection (set theory)|Intersection]]
|<math>L_1 \cap L_2 = \{w \mid w \in L_1 \land w \in L_2\}</math>
| {{Yes}}
| {{No}}
| {{No}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|[[Complement (set theory)|Complement]]
|<math>\neg L_1 = \{w \mid w \not\in L_1\}</math>
| {{Yes}}
| {{Yes}}
| {{No}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{No}}
|-
|[[Concatenation]]
|<math>L_1\cdot L_2 = \{wz \mid w \in L_1 \land z \in L_2\}</math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|Kleene star
|<math>L_1^{*} = \{\varepsilon\} \cup \{wz \mid w \in L_1 \land z \in L_1^{*}\}</math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|(String) homomorphism <math>h</math>
|<math>h(L_1) = \{h(w) \mid w \in L_1\}</math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{No}}
| {{Yes}}
|-
|ε-free (string) homomorphism <math>h</math>
|<math>h(L_1) = \{h(w) \mid w \in L_1\}</math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|Substitution <math>\varphi</math>
|<math>\varphi(L_1) = \bigcup_{\sigma_1 \cdots \sigma_n \in L_1} \varphi(\sigma_1) \cdot \ldots \cdot \varphi(\sigma_n)</math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{Yes}}
|-
|Inverse homomorphism <math>h^{-1}</math>
|<math>h^{-1}(L_1) = \bigcup_{w \in L_1} h^{-1}(w)</math>
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|Reverse
|<math>L^R = \{w^R \mid w \in L\} </math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|Intersection with a [[regular language]] <math>R</math>
|<math>L \cap R = \{w \mid w \in L \land w \in R\}</math>
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
<!--
|-
|Min
|
| {{Yes}}
| {{Yes}}
| {{No}}
| {{?}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|Max
|
| {{Yes}}
| {{Yes}}
| {{No}}
| {{?}}
| {{No}}
| {{No}}
| {{No}}
|-
|Init
|
| {{Yes}}
| {{No}}
| {{Yes}}
| {{?}}
| {{No}}
| {{No}}
| {{Yes}}
|-
|Cycle
|
| {{Yes}}
| {{No}}
| {{Yes}}
| {{?}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|Shuffle
|
| {{Yes}}
| {{?}}
| {{Yes}}
| {{?}}
| {{?}}
| {{?}}
| {{Yes}}
|-
|Perfect Shuffle
|
| {{Yes}}
| {{?}}
| {{?}}
| {{?}}
| {{?}}
| {{?}}
| {{Yes}}
-->
|}

== Applications ==

=== Programming languages ===
{{Main|Syntax (programming languages)|Compiler compiler}}

A compiler usually has two distinct components. A [[lexical analyzer]], sometimes generated by a tool like [[lex programming tool|<code>lex</code>]], identifies the tokens of the programming language grammar, e.g. [[identifier]]s or [[Keyword (computer programming)|keywords]], numeric and string literals, punctuation and operator symbols, which are themselves specified by a simpler formal language, usually by means of [[regular expressions]]. At the most basic conceptual level, a [[parser]], sometimes generated by a [[parser generator]] like <code>[[yacc]]</code>, attempts to decide if the source program is syntactically valid, that is if it is well formed with respect to the programming language grammar for which the compiler was built.

Of course, compilers do more than just parse the source code – they usually translate it into some executable format. Because of this, a parser usually outputs more than a yes/no answer, typically an [[abstract syntax tree]]. This is used by subsequent stages of the compiler to eventually generate an [[executable]] containing [[machine code]] that runs directly on the hardware, or some [[intermediate code]] that requires a [[virtual machine]] to execute.

=== Formal theories, systems, and proofs ===
[[File:Formal languages.svg|thumb|300px|right|This diagram shows the [[Syntax (logic)|syntactic]] divisions within a [[formal system]]. [[string (computer science)|Strings of symbols]] may be broadly divided into nonsense and [[well-formed formula]]s.  The set of well-formed formulas is divided into [[theorem]]s and non-theorems.]]

{{Main|Theory (mathematical logic)|Formal system}}

In [[mathematical logic]], a ''formal theory'' is a set of [[sentence (mathematical logic)|sentences]] expressed in a formal language.

A ''formal system'' (also called a ''logical calculus'', or a ''logical system'') consists of a formal language together with a [[deductive apparatus]] (also called a ''deductive system''). The deductive apparatus may consist of a set of [[transformation rule]]s, which may be interpreted as valid rules of inference, or a set of [[axiom]]s, or have both. A formal system is used to [[Proof theory|derive]] one expression from one or more other expressions. Although a formal language can be identified with its formulas, a formal system cannot be likewise identified by its theorems. Two formal systems <math>\mathcal{FS}</math> and <math>\mathcal{FS'}</math> may have all the same theorems and yet differ in some significant proof-theoretic way (a formula A may be a syntactic consequence of a formula B in one but not another for instance).

A ''formal proof'' or ''derivation'' is a finite sequence of well-formed formulas (which may be interpreted as sentences, or [[proposition]]s) each of which is an axiom or follows from the preceding formulas in the sequence by a [[rule of inference]]. The last sentence in the sequence is a theorem of a formal system. Formal proofs are useful because their theorems can be interpreted as true propositions.

====Interpretations and models====
{{main|Formal semantics (logic)||Interpretation (logic)|Model theory}}

Formal languages are entirely syntactic in nature but may be given [[semantics]] that give meaning to the elements of the language. For instance, in mathematical [[logic]], the set of possible formulas of a particular logic is a formal language, and an [[interpretation (logic)|interpretation]] assigns a meaning to each of the formulas—usually, a [[truth value]].

The study of interpretations of formal languages is called [[Formal semantics (logic)|formal semantics]].  In mathematical logic, this is often done in terms of [[model theory]].  In model theory, the terms that occur in a formula are interpreted as objects within [[Structure (mathematical logic)|mathematical structures]], and fixed compositional interpretation rules determine how the truth value of the formula can be derived from the interpretation of its terms; a ''model'' for a formula is an interpretation of terms such that the formula becomes true.

== See also ==
* [[Combinatorics on words]]
* [[Free monoid]]
* [[Formal method]]
* [[Grammar framework]]
* [[Mathematical notation]]
* [[Associative array]]
* [[String (computer science)]]

== Notes ==
{{NoteFoot}}

== References ==
=== Citations ===
{{Reflist}}

=== Sources ===
; Works cited
{{refbegin}}
* {{wikicite |ref = {{sfnRef|Hopcroft|Ullman|1979}} |reference=[[John Hopcroft|John E. Hopcroft]] and [[Jeffrey Ullman|Jeffrey D. Ullman]], ''[[Introduction to Automata Theory, Languages, and Computation]]'', Addison-Wesley Publishing, Reading Massachusetts, 1979. {{ISBN|81-7808-347-7}}.}}
{{refend}}

; General references
{{refbegin}}
* A. G. Hamilton, ''Logic for Mathematicians'', [[Cambridge University Press]], 1978, {{ISBN|0-521-21838-1}}.
* [[Seymour Ginsburg]], ''Algebraic and automata theoretic properties of formal languages'', North-Holland, 1975, {{ISBN|0-7204-2506-9}}.
* [[Michael A. Harrison]], ''Introduction to Formal Language Theory'', Addison-Wesley, 1978.
* {{cite book |last=Rautenberg |first=Wolfgang |author-link = Wolfgang Rautenberg |doi = 10.1007/978-1-4419-1221-3 |title = A Concise Introduction to Mathematical Logic |publisher=[[Springer Science+Business Media]] |location=[[New York City|New York]], NY |edition=3rd |isbn = 978-1-4419-1220-6 |year=2010 |ref=harv }}.
* [[Grzegorz Rozenberg]], [[Arto Salomaa]], ''Handbook of Formal Languages: Volume I-III'', Springer, 1997, {{ISBN|3-540-61486-9}}.
* Patrick Suppes, ''Introduction to Logic'', D. Van Nostrand, 1957, {{ISBN|0-442-08072-7}}.
{{refend}}

==External links==
{{Commonscat|Formal languages}}
*{{springer|title=Formal language|id=p/f040830}}
*{{planetmath reference|id=1681|title=Alphabet}}
*{{planetmath reference|id=1767|title=Language}}
*[[University of Maryland, Baltimore|University of Maryland]], [http://www.csee.umbc.edu/help/theory/lang_def.shtml Formal Language Definitions]
* James Power, [http://www.cs.nuim.ie/~jpower/Courses/parsing/ "Notes on Formal Language Theory and Parsing"], 29 November 2002.
* Drafts of some chapters in the "Handbook of Formal Language Theory", Vol. 1–3, G. Rozenberg and A. Salomaa (eds.), [[Springer Verlag]], (1997):
** Alexandru Mateescu and Arto Salomaa, [https://www.cs.cmu.edu/~lkontor/noam/Mateescu-Salomaa.pdf "Preface" in Vol.1, pp. v–viii, and "Formal Languages: An Introduction and a Synopsis", Chapter 1 in Vol. 1, pp.1–39]
** Sheng Yu, [http://www.csd.uwo.ca/~syu/public/draft.ps "Regular Languages", Chapter 2 in Vol. 1]
** Jean-Michel Autebert, Jean Berstel, Luc Boasson, [http://citeseer.ist.psu.edu/248295.html "Context-Free Languages and Push-Down Automata", Chapter 3 in Vol. 1]
** Christian Choffrut and Juhani Karhumäki, [http://www.liafa.jussieu.fr/~cc/PUBLICATIONS/CKTUCS.PS.gz "Combinatorics of Words", Chapter 6 in Vol. 1]
** Tero Harju and Juhani Karhumäki, [http://users.utu.fi/harju/articles/morph.pdf "Morphisms", Chapter 7 in Vol. 1, pp. 439–510]
** Jean-Eric Pin, [http://www.liafa.jussieu.fr/~jep/PDF/HandBook.pdf "Syntactic semigroups", Chapter 10 in Vol. 1, pp. 679–746]
** M. Crochemore and C. Hancart, [http://www-igm.univ-mlv.fr/~mac/REC/DOC/B4.ps "Automata for matching patterns", Chapter 9 in Vol. 2]
** Dora Giammarresi, Antonio Restivo, [https://web.archive.org/web/20071008170115/http://bruno.maitresdumonde.com/optinfo/Spe-MP/dmds1998/2dlang/giammaresi-restivo-paper.ps "Two-dimensional Languages", Chapter 4 in Vol. 3, pp. 215–267]

{{Formal languages and grammars}}
{{Mathematical logic}}

{{Authority control}}

{{DEFAULTSORT:Formal Language}}
[[Category:Formal languages| ]]
[[Category:Theoretical computer science]]
[[Category:Combinatorics on words]]{{short description|Words whose letters are taken from an alphabet and are well-formed according to a specific set of rules}}
{{About|a technical term in mathematics and computer science|related studies about natural languages|Formal semantics (linguistics)| formal modes of speech in natural languages|Register (sociolinguistics)}}
{{Use dmy dates|date=July 2013}}
[[File:Syntax tree.svg|thumb|Structure of the syntactically well-formed, although nonsensical, English sentence, ''"Colorless green ideas sleep furiously"'' ([[Colorless green ideas sleep furiously|historical example]] from [[Noam Chomsky|Chomsky]] 1957).]]
In [[mathematics]], [[computer science]], and [[linguistics]], a '''formal language''' consists of [[string (computer science)|words]] whose [[symbol (formal)|letters]] are taken from an [[alphabet (computer science)|alphabet]] and are [[well-formedness|well-formed]] according to a specific set of rules.

The [[Alphabet (computer science)|alphabet]] of a formal language consist of symbols, letters, or tokens that concatenate into strings of the language.<ref>See e.g. {{citation|title=Formal Languages and Compilation|series=Texts in Computer Science|first=Stefano Crespi|last=Reghizzi|publisher=Springer|year=2009|isbn=9781848820500|page=8|quote=An alphabet is a finite set}}.</ref> Each string concatenated from symbols of this alphabet is called a word, and the words that belong to a particular formal language are sometimes called ''well-formed words'' or ''[[well-formed formula]]s''. A formal language is often defined by means of a [[formal grammar]] such as a [[regular grammar]] or [[context-free grammar]], which consists of its [[formation rule]]s.

The field of '''formal language theory''' studies primarily the purely [[syntax|syntactical]] aspects of such languages—that is, their internal structural patterns. Formal language theory sprang out of linguistics, as a way of understanding the syntactic regularities of [[natural language]]s.
In computer science, formal languages are used among others as the basis for defining the grammar of [[programming language]]s and formalized versions of subsets of natural languages in which the words of the language represent concepts that are associated with particular meanings or [[semantics]]. In [[computational complexity theory]], [[decision problem]]s are typically defined as formal languages, and [[complexity class]]es are defined as the sets of the formal languages that can be [[parser|parsed by machines]] with limited computational power. In [[logic]] and the [[foundations of mathematics]], formal languages are used to represent the syntax of [[axiomatic system]]s, and [[Formalism (mathematics)|mathematical formalism]] is the philosophy that all of mathematics can be reduced to the syntactic manipulation of formal languages in this way.

== History ==
{{Expand section|date=April 2011}}
The first formal language is thought to be the one used by [[Gottlob Frege]] in his ''[[Begriffsschrift]]'' (1879), literally meaning "concept writing", and which Frege described as a "formal language of pure thought."<ref name="Herken1995">{{cite book|editor=Rolf Herken|title=The universal Turing machine: a half-century survey|chapter-url=https://books.google.com/books?id=YafIDVd1Z68C&pg=PA290|year=1995|publisher=Springer|isbn=978-3-211-82637-9|page=290|chapter=Influences of Mathematical Logic on Computer Science|author=Martin Davis}}</ref>

[[Axel Thue]]'s early [[semi-Thue system]], which can be used for rewriting strings, was influential on [[formal grammar]]s.

== Words over an alphabet ==
An '''alphabet''', in the context of formal languages, can be any [[set (mathematics)|set]], although it often makes sense to use an [[alphabet]] in the usual sense of the word, or more generally a [[character set]] such as [[ASCII]] or [[Unicode]].  The elements of an alphabet are called its '''letters'''.  An alphabet may contain an [[countable set|infinite]] number of elements;{{NoteTag|For example, [[first-order logic]] is often expressed using an alphabet that, besides symbols such as ∧, ¬, ∀ and parentheses, contains infinitely many elements ''x''<sub>0</sub>,&nbsp;''x''<sub>1</sub>,&nbsp;''x''<sub>2</sub>,&nbsp;… that play the role of variables.}} however, most definitions in formal language theory specify alphabets with a finite number of elements, and most results apply only to them.

A '''word''' over an alphabet can be any finite sequence (i.e., [[string (computer science)|string]]) of letters. The set of all words over an alphabet Σ is usually denoted by Σ<sup>*</sup> (using the [[Kleene star]]). The length of a word is the number of letters it is composed of. For any alphabet, there is only one word of length 0, the ''empty word'', which is often denoted by e, ε, λ or even Λ. By [[concatenation]] one can combine two words to form a new word, whose length is the sum of the lengths of the original words. The result of concatenating a word with the empty word is the original word.

In some applications, especially in [[logic]], the alphabet is also known as the ''vocabulary'' and words are known as ''formulas'' or ''sentences''; this breaks the letter/word metaphor and replaces it by a word/sentence metaphor.

==Definition==
A '''formal language''' ''L'' over an alphabet Σ is a [[subset]] of Σ<sup>*</sup>, that is, a set of [[#Words over an alphabet|words]] over that alphabet. Sometimes the sets of words are grouped into expressions, whereas rules and constraints may be formulated for the creation of 'well-formed expressions'.

In computer science and mathematics, which do not usually deal with [[natural language]]s, the adjective "formal" is often omitted as redundant.

While formal language theory usually concerns itself with formal languages that are described by some syntactical rules, the actual definition of the concept "formal language" is only as above: a (possibly infinite) set of finite-length strings composed from a given alphabet, no more and no less.  In practice, there are many languages that can be described by rules, such as [[regular language]]s or [[context-free language]]s.  The notion of a [[formal grammar]] may be closer to the intuitive concept of a "language," one described by syntactic rules. By an abuse of the definition, a particular formal language is often thought of as being equipped with a formal grammar that describes it.

==Examples==

The following rules describe a formal language&nbsp;{{mvar|L}} over the alphabet Σ&nbsp;=&nbsp;{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, +, =}:
* Every nonempty string that does not contain "+" or "=" and does not start with "0" is in&nbsp;{{mvar|L}}.
* The string "0" is in&nbsp;{{mvar|L}}.
* A string containing "=" is in&nbsp;{{mvar|L}} if and only if there is exactly one "=", and it separates two valid strings of&nbsp;{{mvar|L}}.
* A string containing "+" but not "=" is in&nbsp;{{mvar|L}} if and only if every "+" in the string separates two valid strings of&nbsp;{{mvar|L}}.
* No string is in&nbsp;{{mvar|L}} other than those implied by the previous rules.
Under these rules, the string "23+4=555" is in&nbsp;{{mvar|L}}, but the string "=234=+" is not. This formal language expresses [[natural number]]s, well-formed additions, and well-formed addition equalities, but it expresses only what they look like (their [[syntax]]), not what they mean ([[semantics]]). For instance, nowhere in these rules is there any indication that "0" means the number zero,   "+" means addition, "23+4=555" is false, etc.

=== Constructions ===<!-- [[empty language]] redirects here -->
For finite languages, one can explicitly enumerate all well-formed words. For example, we can describe a language&nbsp;{{mvar|L}} as just {{mvar|L}}&nbsp;=&nbsp;{a, b, ab, cba}. The [[degeneracy (mathematics)|degenerate]] case of this construction is the '''empty language''', which contains no words at all (<span class="nounderlines">{{mvar|L}}&nbsp;=&nbsp;[[∅]]</span>).

However, even over a finite (non-empty) alphabet such as Σ&nbsp;=&nbsp;{a,&nbsp;b} there are an infinite number of finite-length words that can potentially be expressed: "a", "abb", "ababba", "aaababbbbaab",&nbsp;.... Therefore, formal languages are typically infinite, and describing an infinite formal language is not as simple as writing ''L''&nbsp;=&nbsp;{a, b, ab, cba}. Here are some examples of formal languages:
* {{mvar|L}} = Σ<sup>*</sup>, the set of ''all'' words over Σ;
* {{mvar|L}} = {a}<sup>*</sup> = {a<sup>''n''</sup>}, where ''n'' ranges over the natural numbers and "a<sup>''n''</sup>" means "a" repeated ''n'' times (this is the set of words consisting only of the symbol "a");
* the set of syntactically correct programs in a given programming language (the syntax of which is usually defined by a [[context-free grammar]]);
* the set of inputs upon which a certain [[Turing machine]] halts; or
* the set of maximal strings of [[alphanumeric]] [[ASCII]] characters on this line, i.e.,<br> the set {the, set, of, maximal, strings, alphanumeric, ASCII, characters, on, this, line, i, e}.

== Language-specification formalisms ==

Formal languages are used as tools in multiple disciplines. However, formal language theory rarely concerns itself with particular languages (except as examples), but is mainly concerned with the study of various types of formalisms to describe languages. For instance, a language can be given as
* those strings generated by some [[formal grammar]];
* those strings described or matched by a particular [[regular expression]];
* those strings accepted by some [[Automata theory|automaton]], such as a [[Turing machine]] or [[Finite-state machine|finite-state automaton]];
* those strings for which some [[decision problem|decision procedure]] (an [[algorithm]] that asks a sequence of related YES/NO questions) produces the answer YES.

Typical questions asked about such formalisms include:

* What is their expressive power? (Can formalism ''X'' describe every language that formalism ''Y'' can describe? Can it describe other languages?)
* What is their recognizability? (How difficult is it to decide whether a given word belongs to a language described by formalism ''X''?)
* What is their comparability? (How difficult is it to decide whether two languages, one described in formalism ''X'' and one in formalism ''Y'', or in ''X'' again, are actually the same language?).

Surprisingly often, the answer to these decision problems is "it cannot be done at all", or "it is extremely expensive" (with a characterization of how expensive). Therefore, formal language theory is a major application area of [[Computability theory (computer science)|computability theory]] and [[computational complexity theory|complexity theory]]. Formal languages may be classified in the [[Chomsky hierarchy]] based on the expressive power of their generative grammar as well as the complexity of their recognizing [[automata theory|automaton]]. [[Context-free grammar]]s and [[regular grammar]]s provide a good compromise between expressivity and ease of [[parsing]], and are widely used in practical applications.

== Operations on languages ==

Certain operations on languages are common. This includes the standard set operations, such as union, intersection, and complement. Another class of operation is the element-wise application of string operations.

Examples: suppose <math>L_1</math> and <math>L_2</math> are languages over some common alphabet <math>\Sigma</math>.
* The ''[[concatenation]]'' <math>L_1 \cdot L_2</math> consists of all strings of the form <math>vw</math> where <math>v</math> is a string from <math>L_1</math> and <math>w</math> is a string from <math>L_2</math>.
* The ''intersection'' <math>L_1 \cap L_2</math> of <math>L_1</math> and <math>L_2</math> consists of all strings that are contained in both languages
* The ''complement'' <math>\neg L_1</math> of <math>L_1</math> with respect to <math>\Sigma</math> consists of all strings over <math>\Sigma</math> that are not in <math>L_1</math>.
* The [[Kleene star]]: the language consisting of all words that are concatenations of zero or more words in the original language;
* ''Reversal'':
** Let ''ε'' be the empty word, then <math>\varepsilon^R = \varepsilon</math>, and
** for each non-empty word <math>w = \sigma_1 \cdots \sigma_n</math> (where <math>\sigma_1, \ldots, \sigma_n</math>are elements of some alphabet), let <math>w^R = \sigma_n \cdots \sigma_1</math>,
** then for a formal language <math>L</math>, <math>L^R = \{ w^R \mid w \in L \}</math>.
* [[String homomorphism]]

Such [[string operations]] are used to investigate [[Closure (mathematics)|closure properties]] of classes of languages. A class of languages is closed under a particular operation when the operation, applied to languages in the class, always produces a language in the same class again. For instance, the [[context-free language]]s are known to be closed under union, concatenation, and intersection with [[regular language]]s, but not closed under intersection or complement. The theory of [[cone (formal languages)|trios]] and [[abstract family of languages|abstract families of languages]] studies the most common closure properties of language families in their own right.<ref>{{harvtxt|Hopcroft|Ullman|1979}}, Chapter 11: Closure properties of families of languages.</ref>

:{| class="wikitable"
|+ align="top"|Closure properties of language families (<math>L_1</math> Op <math>L_2</math> where both <math>L_1</math> and <math>L_2</math> are in the language family given by the column). After Hopcroft and Ullman.
|-
! Operation
!
! [[Regular language|Regular]]
! [[Deterministic context-free language|DCFL]]
! [[Context free language|CFL]]
! [[Indexed language|IND]]
! [[Context sensitive language|CSL]]
! [[Recursive language|recursive]]
! [[Recursively enumerable language|RE]]
|-
|[[Union (set theory)|Union]]
|<math>L_1 \cup L_2 = \{w \mid w \in L_1 \lor w \in L_2\} </math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|[[Intersection (set theory)|Intersection]]
|<math>L_1 \cap L_2 = \{w \mid w \in L_1 \land w \in L_2\}</math>
| {{Yes}}
| {{No}}
| {{No}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|[[Complement (set theory)|Complement]]
|<math>\neg L_1 = \{w \mid w \not\in L_1\}</math>
| {{Yes}}
| {{Yes}}
| {{No}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{No}}
|-
|[[Concatenation]]
|<math>L_1\cdot L_2 = \{wz \mid w \in L_1 \land z \in L_2\}</math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|Kleene star
|<math>L_1^{*} = \{\varepsilon\} \cup \{wz \mid w \in L_1 \land z \in L_1^{*}\}</math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|(String) homomorphism <math>h</math>
|<math>h(L_1) = \{h(w) \mid w \in L_1\}</math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{No}}
| {{Yes}}
|-
|ε-free (string) homomorphism <math>h</math>
|<math>h(L_1) = \{h(w) \mid w \in L_1\}</math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|Substitution <math>\varphi</math>
|<math>\varphi(L_1) = \bigcup_{\sigma_1 \cdots \sigma_n \in L_1} \varphi(\sigma_1) \cdot \ldots \cdot \varphi(\sigma_n)</math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{Yes}}
|-
|Inverse homomorphism <math>h^{-1}</math>
|<math>h^{-1}(L_1) = \bigcup_{w \in L_1} h^{-1}(w)</math>
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|Reverse
|<math>L^R = \{w^R \mid w \in L\} </math>
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|Intersection with a [[regular language]] <math>R</math>
|<math>L \cap R = \{w \mid w \in L \land w \in R\}</math>
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
<!--
|-
|Min
|
| {{Yes}}
| {{Yes}}
| {{No}}
| {{?}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|Max
|
| {{Yes}}
| {{Yes}}
| {{No}}
| {{?}}
| {{No}}
| {{No}}
| {{No}}
|-
|Init
|
| {{Yes}}
| {{No}}
| {{Yes}}
| {{?}}
| {{No}}
| {{No}}
| {{Yes}}
|-
|Cycle
|
| {{Yes}}
| {{No}}
| {{Yes}}
| {{?}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|-
|Shuffle
|
| {{Yes}}
| {{?}}
| {{Yes}}
| {{?}}
| {{?}}
| {{?}}
| {{Yes}}
|-
|Perfect Shuffle
|
| {{Yes}}
| {{?}}
| {{?}}
| {{?}}
| {{?}}
| {{?}}
| {{Yes}}
-->
|}

== Applications ==

=== Programming languages ===
{{Main|Syntax (programming languages)|Compiler compiler}}

A compiler usually has two distinct components. A [[lexical analyzer]], sometimes generated by a tool like [[lex programming tool|<code>lex</code>]], identifies the tokens of the programming language grammar, e.g. [[identifier]]s or [[Keyword (computer programming)|keywords]], numeric and string literals, punctuation and operator symbols, which are themselves specified by a simpler formal language, usually by means of [[regular expressions]]. At the most basic conceptual level, a [[parser]], sometimes generated by a [[parser generator]] like <code>[[yacc]]</code>, attempts to decide if the source program is syntactically valid, that is if it is well formed with respect to the programming language grammar for which the compiler was built.

Of course, compilers do more than just parse the source code – they usually translate it into some executable format. Because of this, a parser usually outputs more than a yes/no answer, typically an [[abstract syntax tree]]. This is used by subsequent stages of the compiler to eventually generate an [[executable]] containing [[machine code]] that runs directly on the hardware, or some [[intermediate code]] that requires a [[virtual machine]] to execute.

=== Formal theories, systems, and proofs ===
[[File:Formal languages.svg|thumb|300px|right|This diagram shows the [[Syntax (logic)|syntactic]] divisions within a [[formal system]]. [[string (computer science)|Strings of symbols]] may be broadly divided into nonsense and [[well-formed formula]]s.  The set of well-formed formulas is divided into [[theorem]]s and non-theorems.]]

{{Main|Theory (mathematical logic)|Formal system}}

In [[mathematical logic]], a ''formal theory'' is a set of [[sentence (mathematical logic)|sentences]] expressed in a formal language.

A ''formal system'' (also called a ''logical calculus'', or a ''logical system'') consists of a formal language together with a [[deductive apparatus]] (also called a ''deductive system''). The deductive apparatus may consist of a set of [[transformation rule]]s, which may be interpreted as valid rules of inference, or a set of [[axiom]]s, or have both. A formal system is used to [[Proof theory|derive]] one expression from one or more other expressions. Although a formal language can be identified with its formulas, a formal system cannot be likewise identified by its theorems. Two formal systems <math>\mathcal{FS}</math> and <math>\mathcal{FS'}</math> may have all the same theorems and yet differ in some significant proof-theoretic way (a formula A may be a syntactic consequence of a formula B in one but not another for instance).

A ''formal proof'' or ''derivation'' is a finite sequence of well-formed formulas (which may be interpreted as sentences, or [[proposition]]s) each of which is an axiom or follows from the preceding formulas in the sequence by a [[rule of inference]]. The last sentence in the sequence is a theorem of a formal system. Formal proofs are useful because their theorems can be interpreted as true propositions.

====Interpretations and models====
{{main|Formal semantics (logic)||Interpretation (logic)|Model theory}}

Formal languages are entirely syntactic in nature but may be given [[semantics]] that give meaning to the elements of the language. For instance, in mathematical [[logic]], the set of possible formulas of a particular logic is a formal language, and an [[interpretation (logic)|interpretation]] assigns a meaning to each of the formulas—usually, a [[truth value]].

The study of interpretations of formal languages is called [[Formal semantics (logic)|formal semantics]].  In mathematical logic, this is often done in terms of [[model theory]].  In model theory, the terms that occur in a formula are interpreted as objects within [[Structure (mathematical logic)|mathematical structures]], and fixed compositional interpretation rules determine how the truth value of the formula can be derived from the interpretation of its terms; a ''model'' for a formula is an interpretation of terms such that the formula becomes true.

== See also ==
* [[Combinatorics on words]]
* [[Free monoid]]
* [[Formal method]]
* [[Grammar framework]]
* [[Mathematical notation]]
* [[Associative array]]
* [[String (computer science)]]

== Notes ==
{{NoteFoot}}

== References ==
=== Citations ===
{{Reflist}}

=== Sources ===
; Works cited
{{refbegin}}
* {{wikicite |ref = {{sfnRef|Hopcroft|Ullman|1979}} |reference=[[John Hopcroft|John E. Hopcroft]] and [[Jeffrey Ullman|Jeffrey D. Ullman]], ''[[Introduction to Automata Theory, Languages, and Computation]]'', Addison-Wesley Publishing, Reading Massachusetts, 1979. {{ISBN|81-7808-347-7}}.}}
{{refend}}

; General references
{{refbegin}}
* A. G. Hamilton, ''Logic for Mathematicians'', [[Cambridge University Press]], 1978, {{ISBN|0-521-21838-1}}.
* [[Seymour Ginsburg]], ''Algebraic and automata theoretic properties of formal languages'', North-Holland, 1975, {{ISBN|0-7204-2506-9}}.
* [[Michael A. Harrison]], ''Introduction to Formal Language Theory'', Addison-Wesley, 1978.
* {{cite book |last=Rautenberg |first=Wolfgang |author-link = Wolfgang Rautenberg |doi = 10.1007/978-1-4419-1221-3 |title = A Concise Introduction to Mathematical Logic |publisher=[[Springer Science+Business Media]] |location=[[New York City|New York]], NY |edition=3rd |isbn = 978-1-4419-1220-6 |year=2010 |ref=harv }}.
* [[Grzegorz Rozenberg]], [[Arto Salomaa]], ''Handbook of Formal Languages: Volume I-III'', Springer, 1997, {{ISBN|3-540-61486-9}}.
* Patrick Suppes, ''Introduction to Logic'', D. Van Nostrand, 1957, {{ISBN|0-442-08072-7}}.
{{refend}}

==External links==
{{Commonscat|Formal languages}}
*{{springer|title=Formal language|id=p/f040830}}
*{{planetmath reference|id=1681|title=Alphabet}}
*{{planetmath reference|id=1767|title=Language}}
*[[University of Maryland, Baltimore|University of Maryland]], [http://www.csee.umbc.edu/help/theory/lang_def.shtml Formal Language Definitions]
* James Power, [http://www.cs.nuim.ie/~jpower/Courses/parsing/ "Notes on Formal Language Theory and Parsing"], 29 November 2002.
* Drafts of some chapters in the "Handbook of Formal Language Theory", Vol. 1–3, G. Rozenberg and A. Salomaa (eds.), [[Springer Verlag]], (1997):
** Alexandru Mateescu and Arto Salomaa, [https://www.cs.cmu.edu/~lkontor/noam/Mateescu-Salomaa.pdf "Preface" in Vol.1, pp. v–viii, and "Formal Languages: An Introduction and a Synopsis", Chapter 1 in Vol. 1, pp.1–39]
** Sheng Yu, [http://www.csd.uwo.ca/~syu/public/draft.ps "Regular Languages", Chapter 2 in Vol. 1]
** Jean-Michel Autebert, Jean Berstel, Luc Boasson, [http://citeseer.ist.psu.edu/248295.html "Context-Free Languages and Push-Down Automata", Chapter 3 in Vol. 1]
** Christian Choffrut and Juhani Karhumäki, [http://www.liafa.jussieu.fr/~cc/PUBLICATIONS/CKTUCS.PS.gz "Combinatorics of Words", Chapter 6 in Vol. 1]
** Tero Harju and Juhani Karhumäki, [http://users.utu.fi/harju/articles/morph.pdf "Morphisms", Chapter 7 in Vol. 1, pp. 439–510]
** Jean-Eric Pin, [http://www.liafa.jussieu.fr/~jep/PDF/HandBook.pdf "Syntactic semigroups", Chapter 10 in Vol. 1, pp. 679–746]
** M. Crochemore and C. Hancart, [http://www-igm.univ-mlv.fr/~mac/REC/DOC/B4.ps "Automata for matching patterns", Chapter 9 in Vol. 2]
** Dora Giammarresi, Antonio Restivo, [https://web.archive.org/web/20071008170115/http://bruno.maitresdumonde.com/optinfo/Spe-MP/dmds1998/2dlang/giammaresi-restivo-paper.ps "Two-dimensional Languages", Chapter 4 in Vol. 3, pp. 215–267]

{{Formal languages and grammars}}
{{Mathematical logic}}

{{Authority control}}

{{DEFAULTSORT:Formal Language}}
[[Category:Formal languages| ]]
[[Category:Theoretical computer science]]
[[Category:Combinatorics on words]]
'''Causal decision theory''' is a mathematical theory intended to determine the set of [[rational choice|rational choices]] in a given situation.  It is a school of thought in [[decision theory]]. In informal terms, it maintains that the rational choice is that with the best [[expected value|expected]] [[Causality|causal]] consequences. This theory is often contrasted with [[evidential decision theory]], which recommends those actions that provide the best expected outcome conditional on one’s best evidence about the world.

==Informal description==

Informally, causal decision theory recommends the agent to make the decision with the best expected causal consequences. For example: if eating an apple will cause you to be happy and eating an orange will cause you to be sad then you would be rational to eat the apple. One complication is the notion of ''expected'' causal consequences. Imagine that eating a good apple will cause you to be happy and eating a bad apple will cause you to be sad but you aren't sure if the apple is good or bad. In this case you don't know the causal effects of eating the apple. Instead, then, you work from the ''expected'' causal effects, where these will depend on three things: (1) how likely you think the apple is to be good and how likely you think it is to be bad; (2) how happy eating a good apple makes you; and (3) how sad eating a bad apple makes you. In informal terms, causal decision theory advises the agent to make the decision with the best expected causal effects.

==Formal description==

In a 1981 article, Allan Gibbard and William Harper explained causal decision theory as maximization of the expected utility <math>U</math> of an action <math>A</math> "calculated from probabilities of [[Counterfactual conditional|counterfactuals]]":<ref name="GibbardHarper">{{Citation
 | title = Counterfactuals and two kinds of expected utility
 | year = 1981
 | journal = Ifs: Conditionals, Beliefs, Decision, Chance, and Time
 | pages = 153–190
 | last1 = Gibbard       | first1 =  A.
 | last2 =  Harper       | first2 =  W.L.}}</ref>
:<math>
U(A)=\sum\limits_{j} P(A > O_j) D(O_j),
</math>
where <math>D(O_j)</math> is the desirability of outcome <math>O_j</math> and <math>P(A > O_j)</math> is the counterfactual probability that, if <math>A</math> were done, then <math>O_j</math> would hold.

==Difference from evidential decision theory==

[[David Kellogg Lewis|David Lewis]] proved<ref name=Lewis1976>{{Citation
 | doi = 10.2307/2184045
 | title = Probabilities of conditionals and conditional probabilities
 | year = 1976
 | author = Lewis, D.
 | journal = The Philosophical Review
 | pages = 297–315| volume = 85
 | issue = 3
 | jstor = 2184045
}}</ref> that the probability of a conditional <math>P(A > O_j)</math> does not always equal the conditional probability <math>P(O_j | A)</math>.<ref>In fact, Lewis proved a stronger result: "if a class of probability functions is closed under conditionalizing, then there can be no probability conditional for that class unless the class consists entirely of trivial probability functions," where a ''trivial probability function'' is one that "never assigns positive probability to more than two incompatible alternatives, and hence is at most four-valued [...]."</ref> If that were the case, causal decision theory would be equivalent to evidential decision theory, which uses conditional probabilities.

Gibbard and Harper showed that if we accept two axioms (one related to the controversial [[principle of the conditional excluded middle]]<ref name=Shaffer2009>{{Citation
 | title = Decision Theory, Intelligent Planning and Counterfactuals
 | year = 2009
 | author = Shaffer, Michael John
 | journal = Minds and Machines
 | pages = 61–92
 | volume = 19
 | issue = 1
 | doi = 10.1007/s11023-008-9126-2
}}</ref>), then the [[statistical independence]] of <math>A</math> and <math>A > O_j</math> suffices to guarantee that <math>P(A > O_j) = P(O_j | A)</math>. However, there are cases in which actions and conditionals are not independent. Gibbard and Harper give an example in which King David wants Bathsheba but fears that summoning her would provoke a revolt.
<blockquote>
Further, David has studied works on psychology and political science which teach him the following: Kings have two personality types, charismatic and uncharismatic. A king's degree of charisma depends on his genetic make-up and early childhood experiences, and cannot be changed in adulthood. Now, charismatic kings tend to act justly and uncharismatic kings unjustly. Successful revolts against charismatic kings are rare, whereas successful revolts against uncharismatic kings are frequent. Unjust acts themselves, though, do not cause successful revolts; the reason uncharismatic kings are prone to successful revolts is that they have a sneaky, ignoble bearing. David does not know whether or not he is charismatic; he does know that it is unjust to send for another man's wife. (p. 164)
</blockquote>
In this case, evidential decision theory recommends that David abstain from Bathsheba, while causal decision theory—noting that whether David is charismatic or uncharismatic cannot be changed—recommends sending for her.

When required to choose between causal decision theory and evidential decision theory, philosophers usually prefer causal decision theory.<ref>Weirich, Paul, "Causal Decision Theory", The Stanford Encyclopedia of Philosophy (Winter 2016 Edition), Edward N. Zalta (ed.), URL = {{url|https://plato.stanford.edu/archives/win2016/entries/decision-causal/}}</ref>

==Criticism==
===Vagueness===
The theory of causal decision theory (CDT) does not itself specify what algorithm to use to calculate the counterfactual probabilities.<ref name=Shaffer2009 /> One proposal is the "imaging" technique suggested by Lewis:<ref name=Lewis1981>{{Citation
 | doi = 10.1080/00048408112340011
 | title = Causal decision theory
 | url = http://www.informaworld.com/index/739194078.pdf
 | year = 1981
 | author = Lewis, D.
 | journal = Australasian Journal of Philosophy
 | pages = 5–30
 | volume = 59
 | issue = 1
 | accessdate = 2009-05-29
}}</ref> To evaluate <math>P(A > O_j)</math>, move probability mass from each possible world <math>w</math> to the closest possible world <math>w_A</math> in which <math>A</math> holds, assuming <math>A</math> is possible. However, this procedure requires that we know what we would believe if we were certain of <math>A</math>; this is itself a conditional to which we might assign probability less than 1, leading to regress.<ref name=Shaffer2009 />

===Counterexamples===
There are innumerable "counterexamples" where, it is argued, a straightforward application of CDT fails to produce a defensibly "sane" decision. Philosopher Andy Egan argues this is due to a fundamental disconnect between the intuitive rational rule, "do what you expect will bring about the best results", and CDT's algorithm of "do whatever has the best expected outcome, holding fixed our initial views about the likely causal structure of the world." In this view, it is CDT's requirement to "hold fixed the agent’s unconditional credences in dependency hypotheses" that leads to irrational decisions.<ref name=Egan2007 />

An early alleged counterexample is [[Newcomb's problem]]. Because your choice of one or two boxes can't causally affect the Predictor's guess, causal decision theory recommends the two-boxing strategy.<ref name="GibbardHarper" /> However, this results in getting only $1,000, not $1,000,000. Philosophers disagree whether one-boxing or two-boxing is the "rational" strategy.<ref>{{cite news|last1=Bellos|first1=Alex|title=Newcomb's problem divides philosophers. Which side are you on?|url=https://www.theguardian.com/science/alexs-adventures-in-numberland/2016/nov/28/newcombs-problem-divides-philosophers-which-side-are-you-on|accessdate=27 July 2017|work=The Guardian|date=28 November 2016}}</ref> Similar concerns may arise even in seemingly-straightforward problems like the [[prisoner's dilemma]],<ref name=Lewis1979>{{Citation
 | title = Prisoners' dilemma is a Newcomb problem
 | jstor = 2265034
 | year = 1979
 | author = Lewis, D.
 | journal = Philosophy & Public Affairs
 | pages = 235–240| volume = 8
 | issue = 3
 }}</ref> especially when playing opposite your "twin" whose choice to cooperate or defect correlates strongly, but is not caused by, your own choice.<ref>{{cite journal|last1=Howard|first1=J. V.|title=Cooperation in the Prisoner's Dilemma|journal=Theory and Decision|date=May 1988|volume=24|issue=3|pages=203–213|doi=10.1007/BF00148954}}</ref>

In the "Death in Damascus" scenario, an anthropomorphic "Death" predicts where you will be tomorrow, and goes to wait for you there. As in Newcomb's problem, we postulate that Death is a reliable predictor. A CDT agent would be unable to process the correlation, and may as a consequence make irrational decisions:<ref name=Egan2007 /><ref name=binding>Meacham, Christopher JG. "Binding and its consequences." ''Philosophical studies'' 149.1 (2010): 49-71.</ref><ref>{{cite journal|last1=Harper|first1=William|title=Ratifiability and Causal Decision Theory: Comments on Eells and Seidenfeld|journal=PSA: Proceedings of the Biennial Meeting of the Philosophy of Science Association|date=January 1984|volume=1984|issue=2|pages=213–228|doi=10.1086/psaprocbienmeetp.1984.2.192506}}</ref> "You should rather play hide-and-seek against someone who cannot predict where you hide than against someone who can. Causal Decision Theory denies this. So Causal Decision Theory is false."<ref>{{cite journal|last1=Ahmed|first1=A.|title=Dicing with death|journal=Analysis|date=1 September 2014|volume=74|issue=4|pages=587–592|doi=10.1093/analys/anu084}}</ref>

Another recent counterexample is the "Psychopath Button":<ref name=Egan2007>{{Citation 
 |doi=10.1215/00318108-2006-023 
 |title=Some counterexamples to causal decision theory 
 |url=http://andyegan.net/Andy_Egan/Papers_files/nocdt.2006.06.28.pdf 
 |year=2007 
 |author=Egan, A. 
 |journal=The Philosophical Review 
 |pages=93–114 
 |volume=116 
 |issue=1 
 |citeseerx=10.1.1.642.5936 
 |access-date=2017-07-27 
 |archive-url=https://web.archive.org/web/20170311212354/http://www.andyegan.net/Andy_Egan/Papers_files/nocdt.2006.06.28.pdf 
 |archive-date=2017-03-11 
 |url-status=dead 
 }}</ref><ref>Greaves, Hilary. "Epistemic decision theory." Mind 122.488 (2013): 915-952.</ref>

<blockquote>Paul is debating whether to press the ‘kill all psychopaths’ button. It would, he thinks, be much better to live in a world with no psychopaths. Unfortunately, Paul is quite confident that only a psychopath would press such a button. Paul very strongly prefers living in a world with psychopaths to dying. Should Paul press the button?</blockquote>

According to Egan, "pretty much everyone" agrees that Paul should not press the button, yet CDT endorses pressing the button.<ref name=Egan2007 />

Philosopher Jim Joyce, perhaps the most prominent modern defender of CDT,<ref>Wedgwood, Ralph. "Gandalf’s solution to the Newcomb problem." Synthese (2013): 1-33.</ref> argues that CDT naturally is capable of taking into account any "information about what one is inclined or likely to do as evidence". This interpretation of CDT would require solving additional issues: How can a CDT agent avoid stumbling into having beliefs related to its own future acts, and thus becoming provably inconsistent via [[Gödel's incompleteness theorems|Gödelian incompleteness]] and [[Löb's theorem]]? How does the agent standing on a cliff avoid inferring that if he were to jump, he would probably have a parachute to break his fall?<ref name=sep>Weirich, Paul, "Causal Decision Theory", The Stanford Encyclopedia of Philosophy (Winter 2016 Edition), Edward N. Zalta (ed.), URL = {{url|https://plato.stanford.edu/archives/win2016/entries/decision-causal/}}</ref><ref>Joyce, James M. "Regret and instability in causal decision theory." Synthese 187.1 (2012): 123-145.</ref>

== Alternatives to causal and evidential decision theory ==
Some scholars believe that a new decision theory needs to be built from the ground up. Philosopher Christopher Meacham proposes "Cohesive Expected Utility Maximization": An agent "should perform the act picked out by a comprehensive strategy which maximizes cohesive expected utility". Meacham also proposes this can be extended to "Global Cohesive Expected Utility Maximization" to enable [[superrationality]]-style cooperation between agents.<ref name=soares>Soares, Nate, and Benja Fallenstein. "Toward Idealized Decision Theory." Machine Intelligence Research Institute. 2014.</ref><ref>Meacham, Christopher JG. "Binding and its consequences." Philosophical studies 149.1 (2010): 49-71.</ref> In the context of AI, bitcoin pioneer Wei Dai proposes "updateless decision theory", which adds to globally cohesive mechanisms the admittedly difficult concept of "logical counterfactuals" to avoid being blackmailed:<ref name=soares/>

<blockquote>Consider an agent that would pay up in response to a counterfactual blackmail. The blackmailer would predict this and blackmail the agent. Now, instead, consider an agent that would refuse to pay up in response to a counterfactual blackmail... The blackmailer would predict this too, and so would not blackmail the agent. Therefore, if we are constructing an agent that might encounter counterfactual blackmail, then it is a better overall policy to construct an agent that would refuse to pay up when blackmailed in this way.</blockquote>

It is an open question whether a satisfactory formalization of logical counterfactuals exists.<ref>Nate Soares and Benja Fallenstein. Counterpossibles as necessary for
decision theory. In Artificial General Intelligence. Springer, 2015.</ref><ref>Everitt, Tom, Jan Leike, and Marcus Hutter. "Sequential extensions of causal and evidential decision theory." International Conference on Algorithmic Decision Theory. Springer, Cham, 2015.</ref>

==See also==
{{colbegin|colwidth=25em}}
* [[Decision making]]
* [[Evidential decision theory]]
* [[Expected utility hypothesis]]
* [[Game theory]]
* [[Newcomb's paradox]]
{{colend}}

==Notes==
{{reflist}}

==External links==
*[http://plato.stanford.edu/entries/decision-causal/ Causal Decision Theory] at the [[Stanford Encyclopedia of Philosophy]]
* [http://plato.stanford.edu/entries/logic-conditionals/ The Logic of Conditionals] at the [[Stanford Encyclopedia of Philosophy]]

{{DEFAULTSORT:Causal Decision Theory}}
[[Category:Decision theory| ]]
{{short description|Interdisciplinary field}}
{{About|the scientific field|the journal|Computational Linguistics (journal)}}
{{Linguistics|Subfields}}

'''Computational linguistics''' is an [[Interdisciplinarity|interdisciplinary]] field concerned with the computational modelling of [[natural language]], as well as the study of appropriate computational approaches to linguistic questions. In general, computational linguistics draws upon [[linguistics]], [[computer science]], [[artificial intelligence]], [[mathematicians|math]], [[logic]], [[philosophy]], [[cognitive science]], [[cognitive psychology]], [[psycholinguistics]], [[anthropology]] and [[neuroscience]], among others.

Traditionally, computational linguistics emerged as an area of [[artificial intelligence]] performed by [[computer scientist]]s who had specialized in the application of computers to the processing of a [[natural language]]. With the formation of the [[Association for Computational Linguistics]] (ACL)<ref>{{Cite web|title=ACL Member Portal {{!}} The Association for Computational Linguistics Member Portal|url=https://www.aclweb.org/portal/|access-date=2020-08-17|website=www.aclweb.org}}</ref> and the establishment of independent conference series, the field consolidated during the 1970s and 1980s. The term "computational linguistics" is nowadays (2020) taken to be a near-synonym of [[natural language processing]] (NLP) and [[Human language technology|(human) language technology]]. These terms put a stronger emphasis on aspects of practical applications rather than theoretical inquiry and since the 2000s, they have largely replaced the term "computational linguistics" in the NLP community.<ref>As pointed out, for example, by Ido Dagan at his speech at the [https://mirror.aclweb.org/acl2010/social.html ACL 2010 banquet] in Uppsala, Sweden.</ref>

Computational linguistics has both theoretical and applied components. Theoretical computational linguistics focuses on issues in [[theoretical linguistics]] and cognitive science.<ref name=":1" /> Applied computational linguistics focuses on the practical outcome of modeling human language use.<ref name=":1">{{cite web |first=Hans |last=Uszkoreit |title=What Is Computational Linguistics? |url=http://www.coli.uni-saarland.de/~hansu/what_is_cl.html |publisher=Department of Computational Linguistics and Phonetics of Saarland University}}</ref> Theoretical computational linguistics includes the development of formal theories of grammar ([[parsing]]) and semantics, often grounded in [[Mathematical logic|formal logics]] and [[Symbolic artificial intelligence|symbolic]] ([[Knowledge-based systems|knowledge-based]]) approaches. Applied computational linguistics is dominated by [[machine learning]], traditionally using [[Statistics|statistical methods]], since the mid-2010s by [[Neural network|neural networks]]: Socher et al. (2012)<ref>{{Cite web|last=Socher|first=Richard|title=Deep Learning For NLP-ACL 2012 Tutorial|url=https://www.socher.org/index.php/Main/DeepLearningForNLP-ACL2012Tutorial|access-date=2020-08-17|website=Socher}}</ref> was an early [[Deep learning|Deep Learning]] tutorial at the ACL 2012, and met with both interest and (at the time) scepticism by most participants. Until then, neural learning was basically rejected because of its lack of statistical interpretability. Until 2015, deep learning had evolved into the major framework of NLP.

The Association for Computational Linguistics defines computational linguistics as:
{{quote|...the scientific study of [[language]] from a computational perspective. Computational linguists are interested in providing [[computational model]]s of various kinds of linguistic phenomena.<ref>{{cite web |publisher=The Association for Computational Linguistics |url=http://www.aclweb.org/archive/misc/what.html |title=What is Computational Linguistics? |date=February 2005}}</ref>}}

==Origins==
Computational linguistics is often grouped within the field of artificial intelligence but was present before the development of artificial intelligence. Computational linguistics originated with efforts in the United States in the 1950s to use computers to automatically translate texts from foreign languages, particularly Russian scientific journals, into English.<ref>John Hutchins: [http://www.hutchinsweb.me.uk/MTS-1999.pdf Retrospect and prospect in computer-based translation.] Proceedings of MT Summit VII, 1999, pp. 30–44.</ref> Since computers can make [[arithmetic]] (systematic) calculations much faster and more accurately than humans, it was thought to be only a short matter of time before they could also begin to process language.<ref>Arnold B. Barach: [https://www.flickr.com/photos/bostworld/2152048032/in/set-72157603898383698/ Translating Machine] 1975: And the Changes To Come.</ref> Computational and quantitative methods are also used historically in the attempted reconstruction of earlier forms of modern languages and sub-grouping modern languages into language families. Earlier methods, such as [[lexicostatistics]] and [[glottochronology]], have been proven to be premature and inaccurate. However, recent interdisciplinary studies that borrow concepts from biological studies, especially [[gene mapping]], have proved to produce more sophisticated analytical tools and more reliable results.<ref>T. Crowley., C. Bowern. An Introduction to Historical Linguistics. Auckland, N.Z.: Oxford UP, 1992. Print.</ref>

When [[machine translation]] (also known as mechanical translation) failed to yield accurate translations right away, automated processing of human languages was recognized as far more complex than had originally been assumed. Computational linguistics was born as the name of the new field of study devoted to developing [[algorithm]]s and software for intelligently processing language data. The term "computational linguistics" itself was first coined by [[David G. Hays|David Hays]], a founding member of both the [[Association for Computational Linguistics|Association for Computational Linguistics (ACL)]] and the [[International Committee on Computational Linguistics]] (ICCL).<ref>{{cite web|url=http://nlp.shef.ac.uk/iccl/committee.html#deceased|title=Deceased members|website=ICCL members|access-date=15 November 2017|ref=ICCLmembers}}</ref>

To translate one language into another, it was observed that one had to understand the [[grammar]] of both languages, including both [[morphology (linguistics)|morphology]] (the grammar of word forms) and [[syntax]] (the grammar of sentence structure). To understand syntax, one had to also understand the [[semantics]] and the [[lexicon]] (or 'vocabulary'), and even something of the [[pragmatics]] of language use. Thus, what started as an effort to translate between languages evolved into an entire discipline devoted to understanding how to represent and process natural languages using computers.<ref>[http://www-nlpir.nist.gov/MINDS/FINAL/NLP.web.pdf Natural Language Processing by Liz Liddy, Eduard Hovy, Jimmy Lin, John Prager, Dragomir Radev, Lucy Vanderwende, Ralph Weischedel]</ref>

Nowadays research within the scope of computational linguistics is done at computational linguistics departments,<ref>[http://www.coli.uni-saarland.de "Computational Linguistics and Phonetics"].</ref> computational linguistics laboratories,<ref>[http://yatsko.zohosites.com/home.html "Yatsko's Computational Linguistics Laboratory"].</ref> [[computer science]] departments,<ref>[https://wiki.umiacs.umd.edu/clip/index.php/Main_Page "CLIP"].</ref> and linguistics departments.<ref>[http://linguistics.georgetown.edu/programs/graduate/computational/ Computational Linguistics&nbsp;– Department of Linguistics&nbsp;– Georgetown College<!-- Bot generated title -->]</ref><ref>[http://www.ling.upenn.edu/research/computational.html "UPenn Linguistics: Computational Linguistics"].</ref> 
Some research in the field of computational linguistics aims to create working speech or text processing systems while others aim to create a system allowing human-machine interaction. Programs meant for human-machine communication are called [[Embodied agent|conversational agents]].<ref>Jurafsky, D., & Martin, J. H. (2009). Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition. Upper Saddle River, N.J: Pearson Prentice Hall.</ref>

==Approaches==

{{Summarize section}}

Just as computational linguistics can be performed by experts in a variety of fields and through a wide assortment of departments, so too can the research fields broach a diverse range of topics. The following sections discuss some of the literature available across the entire field broken into four main area of discourse: developmental linguistics, structural linguistics, linguistic production, and linguistic comprehension.

===Developmental approaches===

Language is a cognitive skill that develops throughout the life of an individual. This developmental process has been examined using several techniques, and a computational approach is one of them. Human [[language development]] does provide some constraints which make it harder to apply a computational method to understanding it. For instance, during [[language acquisition]], human children are largely only exposed to positive evidence.<ref>Bowerman, M. (1988). [http://pubman.mpdl.mpg.de/pubman/item/escidoc:468143:4/component/escidoc:532427/bowerman_1988_The-No.pdf The "no negative evidence" problem: How do children avoid constructing an overly general grammar. Explaining language universals].</ref> This means that during the linguistic development of an individual, the only evidence for what is a correct form is provided, and no evidence for what is not correct. This is insufficient information for a simple hypothesis testing procedure for information as complex as language,<ref name="autogenerated1971">Braine, M.D.S. (1971). On two types of models of the internalization of grammars. In D.I. Slobin (Ed.), The ontogenesis of grammar: A theoretical perspective. New York: Academic Press.</ref> and so provides certain boundaries for a computational approach to modeling language development and acquisition in an individual.

Attempts have been made to model the developmental process of language acquisition in children from a computational angle, leading to both [[stochastic grammar|statistical grammars]] and [[connectionism|connectionist models]].<ref name="powers1989">Powers, D.M.W. & Turk, C.C.R. (1989). ''Machine Learning of Natural Language''. Springer-Verlag. {{ISBN|978-0-387-19557-5}}.</ref> Work in this realm has also been proposed as a method to explain the [[evolution of language]] through history. Using models, it has been shown that languages can be learned with a combination of simple input presented incrementally as the child develops better memory and longer attention span.<ref name="autogenerated1993">{{cite journal|title= Learning and development in neural networks: The importance of starting small|journal= Cognition|volume= 48|issue= 1|pages= 71–99|doi= 10.1016/0010-0277(93)90058-4|pmid= 8403835|year= 1993|last1= Elman|first1= Jeffrey L.|s2cid= 2105042}}</ref> This was simultaneously posed as a reason for the long developmental period of human children.<ref name="autogenerated1993"/> Both conclusions were drawn because of the strength of the [[artificial neural network]] which the project created.

The ability of infants to develop language has also been modeled using robots<ref>{{cite journal | last1 = Salvi | first1 = G. | last2 = Montesano | first2 = L. | last3 = Bernardino | first3 = A. | last4 = Santos-Victor | first4 = J. | year = 2012 | title = Language bootstrapping: learning word meanings from the perception-action association | journal = IEEE Transactions on Systems, Man, and Cybernetics. Part B | volume = 42 | issue = 3| pages = 660–71 | doi = 10.1109/TSMCB.2011.2172420 | pmid = 22106152 | arxiv = 1711.09714 | s2cid = 977486 }}</ref> in order to test linguistic theories. Enabled to learn as children might, a model was created based on an [[affordance]] model in which mappings between actions, perceptions, and effects were created and linked to spoken words. Crucially, these robots were able to acquire functioning word-to-meaning mappings without needing grammatical structure, vastly simplifying the learning process and shedding light on information which furthers the current understanding of linguistic development. It is important to note that this information could only have been empirically tested using a computational approach.

As our understanding of the linguistic development of an individual within a lifetime is continually improved using neural networks and [[Robot learning|learning robotic systems]], it is also important to keep in mind that languages themselves change and develop through time. Computational approaches to understanding this phenomenon have unearthed very interesting information. Using the [[Price equation]] and [[Pólya urn]] dynamics, researchers have created a system which not only predicts future linguistic evolution but also gives insight into the evolutionary history of modern-day languages.<ref>{{cite journal|author1=Gong, T.|author2=Shuai, L.|author3=Tamariz, M.|author4=Jäger, G.|name-list-style=amp|year=2012|title=Studying Language Change Using Price Equation and Pólya-urn Dynamics|editor=E. Scalas|journal=PLOS ONE|volume=7|issue=3|page=e33171|doi=10.1371/journal.pone.0033171|pmid=22427981|pmc=3299756|bibcode=2012PLoSO...733171G}}</ref> This modeling effort achieved, through computational linguistics, what would otherwise have been impossible.

It is clear that the understanding of linguistic development in humans as well as throughout evolutionary time has been fantastically improved because of advances in computational linguistics. The ability to model and modify systems at will affords science an ethical method of testing hypotheses that would otherwise be intractable.

===Structural approaches===

To create better computational models of language, an understanding of language's structure is crucial. To this end, the [[English language]] has been meticulously studied using computational approaches to better understand how the language works on a structural level. One of the most important pieces of being able to study linguistic structure is the availability of large linguistic corpora or samples. This grants computational linguists the raw data necessary to run their models and gain a better understanding of the underlying structures present in the vast amount of data which is contained in any single language. One of the most cited English linguistic corpora is the Penn [[Treebank]].<ref>{{cite journal|author1=Marcus, M.|author2=Marcinkiewicz, M.|name-list-style=amp|year=1993|url=https://www.aclweb.org/anthology/J/J93/J93-2004.pdf|title=Building a large annotated corpus of English: The Penn Treebank|journal=Computational Linguistics|volume=19|issue=2|pages=313–330}}</ref> Derived from widely-different sources, such as IBM computer manuals and transcribed telephone conversations, this corpus contains over 4.5 million words of American English. This corpus has been primarily annotated using [[part-of-speech]] tagging and syntactic bracketing and has yielded substantial empirical observations related to language structure.<ref>{{cite book|last1=Taylor|first1=Ann|title=Treebanks|date=2003|publisher=Spring Netherlands|pages=5–22|chapter=1}}</ref>

Theoretical approaches to the structure of languages have also been developed. These works allow computational linguistics to have a framework within which to work out hypotheses that will further the understanding of the language in a myriad of ways. One of the original theoretical theses on the internalization of [[grammar]] and structure of language proposed two types of models.<ref name="autogenerated1971" /> In these models, rules or patterns learned increase in strength with the frequency of their encounter.<ref name="autogenerated1971" /> The work also created a question for computational linguists to answer: how does an infant learn a specific and non-normal grammar ([[Chomsky normal form]]) without learning an overgeneralized version and getting stuck?<ref name="autogenerated1971" /> Theoretical efforts like these set the direction for research to go early in the lifetime of a field of study, and are crucial to the growth of the field.

Structural information about languages allows for the discovery and implementation of similarity recognition between pairs of text utterances.<ref name="autogenerated2">{{cite journal|author1=Angus, D.|author2=Smith, A.|author3=Wiles, J.|name-list-style=amp|year=2012|title=Conceptual recurrence plots: revealing patterns in human discourse|journal=IEEE Transactions on Visualization and Computer Graphics|volume=18|issue=6|pages=988–97|doi=10.1109/TVCG.2011.100|pmid=22499664|s2cid=359497|url=https://espace.library.uq.edu.au/view/UQ:269425/ERAUQ269425.pdf}}</ref> For instance, it has recently been proven that based on the structural information present in patterns of human discourse, conceptual [[recurrence plots]] can be used to model and visualize trends in data and create reliable measures of similarity between natural textual utterances.<ref name="autogenerated2"/> This technique is a strong tool for further probing the structure of human [[discourse]]. Without the computational approach to this question, the vastly complex information present in discourse data would have remained inaccessible to scientists.

Information regarding the structural data of a language is available for [[English language|English]] as well as other languages, such as [[Japanese language|Japanese]].<ref name="autogenerated3">{{cite journal|author1=Furuhashi, S.|author2=Hayakawa, Y. |name-list-style=amp|year=2012|title=Lognormality of the Distribution of Japanese Sentence Lengths|journal=Journal of the Physical Society of Japan|volume=81|issue=3|page=034004|doi=10.1143/JPSJ.81.034004|bibcode=2012JPSJ...81c4004F }}</ref> Using computational methods, Japanese sentence corpora were analyzed and a pattern of [[log-normality]] was found in relation to sentence length.<ref name="autogenerated3"/> Though the exact cause of this lognormality remains unknown, it is precisely this sort of information which computational linguistics is designed to uncover. This information could lead to further important discoveries regarding the underlying structure of Japanese and could have any number of effects on the understanding of Japanese as a language. Computational linguistics allows for very exciting additions to the scientific knowledge base to happen quickly and with very little room for doubt.

In recent days, the structural data of languages is available for several languages of the world other than [[English language]]. Computational linguistics work is in progress on [[Sindhi language]] because the structure, grammar and domain of [[Sindhi language]] is different from the other languages of the World. The computational linguistics models for English language are not suitable for [[Sindhi language]]. Viewing this, computational linguistics work on Sindhi language <ref>{{Cite web|url=https://www.researchgate.net/profile/Mazhar_Dootio|title=Mazhar Ali Dootio {{!}} PhD (Computer Science) Continue from SZABIST Karachi Sindh Pakistan {{!}} Independent Researcher {{!}} Computer Science {{!}} ResearchGate|website=ResearchGate|access-date=2019-07-16}}</ref><ref>{{Cite web|url=https://scholar.google.com.pk/citations?user=s0L9vIkAAAAJ&hl=en|title=Mazhar Ali Dootio - Google Scholar Citations|website=scholar.google.com.pk|access-date=2019-07-16}}</ref><ref>{{Cite web|url=https://sindhinlp.com/contact.php|title=Sindhi NLP|website=sindhinlp.com|access-date=2019-07-16}}</ref> has been started properly by developing methods, algorithms, linguistics tools (https://sindhinlp.com/), machine learning models and deep learning models since 2016 <ref>{{Cite journal|last1=Dootio|first1=Mazhar Ali|last2=Wagan|first2=Asim Imdad|date=February 2019|title=Development of Sindhi text corpus|journal=Journal of King Saud University - Computer and Information Sciences|doi=10.1016/j.jksuci.2019.02.002|issn=1319-1578|doi-access=free}}</ref><ref>{{Cite journal|last1=Dootio|first1=Mazhar Ali|last2=Wagan|first2=Asim Imdad|date=January 2019|title=Syntactic parsing and supervised analysis of Sindhi text|journal=Journal of King Saud University - Computer and Information Sciences|volume=31|issue=1|pages=105–112|doi=10.1016/j.jksuci.2017.10.004|issn=1319-1578|doi-access=free}}</ref><ref>{{Cite journal|last1=Wagan|first1=Asim Imdad|last2=Ali|first2=Mazhar|date=2019-01-01|title=An Analysis of Sindhi Annotated Corpus using Supervised Machine Learning Methods|url=http://publications.muet.edu.pk/index.php/muetrj/article/view/754|journal=Mehran University Research Journal of Engineering and Technology|volume=38|issue=1|pages=185–196|doi=10.22581/muet1982.1901.15|bibcode=2019MURJE..38..185A|issn=2413-7219|doi-access=free}}</ref><ref>{{Citation|last=Dootio|first=Mazhar Ali|title=AUTOMATIC STEMMING AND LEMMATIZATION PROCESS FOR SINDHI TEXT|date=2017|url=https://www.researchgate.net/publication/328202210|work=Computational Linguistics and Intelligent Text Processing|volume=6|pages=103–112|publisher=JSSIR NED University of Engineering and Technology Karachi Sindh Pakistan}}</ref><ref>{{Cite journal|last1=Dootio|first1=Mazhar Ali|last2=Wagan|first2=Asim Imdad|date=August 2018|title=Unicode-8 based linguistics data set of annotated Sindhi text|journal=Data in Brief|volume=19|pages=1504–1514|doi=10.1016/j.dib.2018.05.062|pmid=30225294|issn=2352-3409|pmc=6139473}}</ref><ref>{{Cite web|url=https://www.researchgate.net/publication/330855516|title=An analysis and solution of computational linguistics problems of Sindhi text|website=ResearchGate|access-date=2019-07-16}}</ref> to focus and solve the linguistics problems of Sindhi language. This work could lead to further important discoveries regarding the underlying structure of Sindhi, and could have any number of effects on the understanding of Sindhi as a language.

Without a computational approach to the structure of linguistic data, much of the information that is available now would still be hidden under the vastness of data within any single language. Computational linguistics allows scientists to parse huge amounts of data reliably and efficiently, creating the possibility for discoveries unlike any seen in most other approaches.

===Production approaches===
{{Original research section|date=October 2015}}

The [[Language production|production of language]] is equally as complex in the information it provides and the necessary skills which a fluent producer must have. That is to say, [[understanding|comprehension]] is only half the problem of communication. The other half is how a system produces language, and computational linguistics has made interesting discoveries in this area.
[[File:Alan Turing Aged 16.jpg|thumb|Alan Turing: computer scientist and namesake developer of the [[Turing test]] as a method of measuring the intelligence of a machine.]]
In a now famous paper published in 1950 [[Alan Turing]] proposed the possibility that machines might one day have the ability to "think". As a [[thought experiment]] for what might define the concept of thought in machines, he proposed an "imitation test" in which a human subject has two text-only conversations, one with a fellow human and another with a machine attempting to respond like a human. Turing proposes that if the subject cannot tell the difference between the human and the machine, it may be concluded that the machine is capable of thought.<ref>{{cite journal|author=Turing, A. M.|year=1950|jstor=2251299|title=Computing machinery and intelligence|journal=Mind|volume=59|issue=236|pages=433–460|doi=10.1093/mind/lix.236.433}}</ref> Today this test is known as the [[Turing test]] and it remains an influential idea in the area of artificial intelligence.

[[File:Joseph Weizenbaum.jpg|thumb|[[Joseph Weizenbaum]]: former MIT professor and computer scientist who developed [[ELIZA]], a primitive computer program utilizing [[natural language processing]].]] One of the earliest and best-known examples of a computer program designed to converse naturally with humans is the [[ELIZA]] program developed by [[Joseph Weizenbaum]] at [[Massachusetts Institute of Technology|MIT]] in 1966. The program emulated a [[Rogerian psychotherapy|Rogerian]] [[psychotherapist]] when responding to written statements and questions posed by a user. It appeared capable of understanding what was said to it and responding intelligently, but in truth, it simply followed a pattern matching routine that relied on only understanding a few keywords in each sentence. Its responses were generated by recombining the unknown parts of the sentence around properly translated versions of the known words. For example, in the phrase "It seems that you hate me" ELIZA understands "you" and "me" which matches the general pattern "you [some words] me", allowing ELIZA to update the words "you" and "me" to "I" and "you" and replying "What makes you think I hate you?". In this example ELIZA has no understanding of the word "hate", but it is not required for a logical response in the context of this type of psychotherapy.<ref>{{cite journal|author=Weizenbaum, J.|year=1966|title=ELIZA—a computer program for the study of natural language communication between man and machine|journal=Communications of the ACM|volume=9|issue=1|pages=36–45|doi=10.1145/365153.365168|s2cid=1896290}}</ref>

Some projects are still trying to solve the problem which first started computational linguistics off as its field in the first place. However, methods have become more refined, and consequently, the results generated by computational linguists have become more enlightening. To improve [[computer translation]], several models have been compared, including [[hidden Markov models]], smoothing techniques, and the specific refinements of those to apply them to verb translation.<ref>{{cite journal|author1=Och, F. J.|author2=Ney, H.|year=2003|title=A Systematic Comparison of Various Statistical Alignment Models|journal=Computational Linguistics|volume=29|issue=1|pages=19–51|doi=10.1162/089120103321337421|doi-access=free}}</ref> The model which was found to produce the most natural translations of [[German language|German]] and [[French language|French]] words was a refined alignment model with a first-order dependence and a fertility model. They also provide efficient training algorithms for the models presented, which can give other scientists the ability to improve further on their results. This type of work is specific to computational linguistics and has applications that could vastly improve understanding of how language is produced and comprehended by computers.

Work has also been done in making computers produce language in a more naturalistic manner. Using linguistic input from humans, algorithms have been constructed which are able to modify a system's style of production based on a factor such as linguistic input from a human, or more abstract factors like politeness or any of the [[Big Five personality traits|five main dimensions of personality]].<ref>{{cite journal|author=Mairesse, F.|year=2011|title=Controlling user perceptions of linguistic style: Trainable generation of personality traits|journal=Computational Linguistics|doi=10.1162/COLI_a_00063|volume=37|issue=3|pages=455–488|doi-access=free}}</ref> This work takes a computational approach via [[parameter estimation]] models to categorize the vast array of linguistic styles we see across individuals and simplify it for a computer to work in the same way, making [[human-computer interaction]] much more natural.

==== Text-based interactive approach ====

Many of the earliest and simplest models of human-computer interaction, such as ELIZA for example, involve a text-based input from the user to generate a response from the computer. By this method, words typed by a user trigger the computer to recognize specific patterns and reply accordingly, through a process known as [[keyword spotting]].

==== Speech-based interactive approach ====

Recent technologies have placed more of an emphasis on speech-based interactive systems. These systems, such as [[Siri]] of the [[iOS]] operating system, operate on a similar pattern-recognizing technique as that of text-based systems, but with the former, the user input is conducted through [[speech recognition]]. This branch of linguistics involves the processing of the user's speech as sound waves and the interpreting of the acoustics and language patterns for the computer to recognize the input.<ref>{{Cite book|title = Language Files|publisher = The Ohio State University Department of Linguistics|year = 2011|isbn = 9780814251799|pages = 624–634}}</ref>

===Comprehension approaches===

Much of the focus of modern computational linguistics is on comprehension. With the proliferation of the internet and the abundance of easily accessible written human language, the ability to create a program capable of [[natural language understanding|understanding human language]] would have many broad and exciting possibilities, including improved search engines, automated customer service, and online education.

Early work in comprehension included applying Bayesian statistics to the task of optical character recognition, as illustrated by Bledsoe and Browing in 1959 in which a large dictionary of possible letters was generated by "learning" from example letters and then the probability that any one of those learned examples matched the new input was combined to make a final decision.<ref>{{cite conference|author1=Bledsoe, W. W.|author2=Browning, I.|name-list-style=amp|year=1959|title=Pattern recognition and reading by machine|conference=Papers presented at the December 1–3, 1959, eastern joint IRE-AIEE-ACM computer conference on – IRE-AIEE-ACM ’59 (Eastern)|pages=225–232|location=New York, New York, USA|publisher=ACM Press|doi=10.1145/1460299.1460326}}</ref> Other attempts at applying Bayesian statistics to language analysis included the work of Mosteller and Wallace (1963) in which an analysis of the words used in ''[[The Federalist Papers]]'' was used to attempt to determine their authorship (concluding that Madison most likely authored the majority of the papers).<ref>{{cite journal|author=Mosteller, F.|year=1963|jstor=2283270|title=Inference in an authorship problem|journal=Journal of the American Statistical Association|volume=58|issue=302|pages=275–309|doi=10.2307/2283270}}</ref>

In 1971 [[Terry Winograd]] developed an early [[natural language processing]] engine capable of interpreting naturally written commands within a simple rule-governed environment. The primary language parsing program in this project was called [[SHRDLU]], which was capable of carrying out a somewhat natural conversation with the user giving it commands, but only within the scope of the toy environment designed for the task. This environment consisted of different shaped and colored blocks, and SHRDLU was capable of interpreting commands such as "Find a block which is taller than the one you are holding and put it into the box." and asking questions such as "I don't understand which pyramid you mean." in response to the user's input.<ref>{{cite journal|author=Winograd, T.|year=1971|url=http://www.dtic.mil/docs/citations/AD0721399|title=Procedures as a Representation for Data in a Computer Program for Understanding Natural Language|type=Report}}</ref> While impressive, this kind of [[natural language processing]] has proven much more difficult outside the limited scope of the toy environment. Similarly, a project developed by [[NASA]] called [[LUNAR]] was designed to provide answers to naturally written questions about the geological analysis of lunar rocks returned by the Apollo missions.<ref>{{cite journal|author1=Woods, W.|author2=Kaplan, R.|author3=Nash-Webber, B.|author3-link=Bonnie Webber|name-list-style=amp|year=1972|url=https://www.researchgate.net/publication/247926251|title=The lunar sciences natural language information system|type=Report}}</ref> These kinds of problems are referred to as [[question answering]].

Initial attempts at understanding spoken language were based on work done in the 1960s and 1970s in signal modeling where an unknown signal is analyzed to look for patterns and to make predictions based on its history. An initial and somewhat successful approach to applying this kind of signal modeling to language was achieved with the use of hidden Markov models as detailed by Rabiner in 1989.<ref>{{cite journal|author=Rabiner, L.|year=1989|title=A tutorial on hidden Markov models and selected applications in speech recognition|journal=Proceedings of the IEEE|volume=77|issue=2|pages=257–286|doi=10.1109/5.18626|citeseerx=10.1.1.381.3454}}</ref> This approach attempts to determine probabilities for the arbitrary number of models that could be being used in generating speech as well as modeling the probabilities for various words generated from each of these possible models. Similar approaches were employed in early [[speech recognition]] attempts starting in the late 70s at IBM using word/part-of-speech pair probabilities.<ref>{{cite journal|author1=Bahl, L.|author2=Baker, J.|author3=Cohen, P.|author4=Jelinek, F.|year=1978|title=Recognition of continuously read natural corpus|journal=Acoustics, Speech, and Signal|volume=3|pages=422–424|doi=10.1109/ICASSP.1978.1170402}}</ref>

More recently these kinds of statistical approaches have been applied to more difficult tasks such as topic identification using Bayesian parameter estimation to infer topic probabilities in text documents.<ref>{{cite journal|author1=Blei, D.|author2=Ng, A. |name-list-style=amp|year=2003|url=http://dl.acm.org/citation.cfm?id=944937|title=Latent dirichlet allocation|journal=The Journal of Machine Learning|volume=3|pages=993–1022}}</ref>

== Applications ==
{{Further|Natural language processing}}
Applied computational linguistics is largely equivalent with [[natural language processing]]. Example applications for end users include speech recognition software, such as Apple's Siri feature, spellcheck tools, [[speech synthesis]] programs, which are often used to demonstrate pronunciation or help the disabled, and machine translation programs and websites, such as Google Translate.<ref name=":0">{{Cite web|url=http://www.cla.csulb.edu/departments/linguistics/careers-computational-linguistics/|title=Careers in Computational Linguistics|publisher=California State University|access-date=19 September 2016}}</ref>

Computational linguistics also be helpful in situations involving [[social media]] and the [[Internet]], e.g., for providing content filters in chatrooms or on website searches,<ref name=":0" /> for grouping and organizing content through [[social media mining]],<ref>Marujo, Lu<math>\acute{i}</math>s et al. "Automatic Keyword Extraction on Twitter." Language Technologies Institute, Carnegie Mellon University, n.d. Web. 19 Sept. 2016.</ref> document retrieval and clustering. For instance, if a person searches "red, large, four-wheeled vehicle," to find pictures of a red truck, the search engine will still find the information desired by matching words such as "four-wheeled" with "car".<ref>{{Cite web|url=https://plato.stanford.edu/entries/computational-linguistics/#DocRetCluApp|title=Computational Linguistics|date=Feb 26, 2014|website=Stanford Encyclopedia of Philosophy|access-date=Apr 19, 2017|publisher=Metaphysics Research Lab, Stanford University}}</ref>

Computational approaches are also important to support linguistic research, e.g., in [[corpus linguistics]]<ref name=":2" /> or [[historical linguistics]]. As for the study of change over time, computational methods can contribute to the modeling and identification of language families<ref name=":3">Bowern, Claire. "Computational phylogenetics." Annual Review of Linguistics 4 (2018): 281-296.</ref> (see further [[Quantitative_comparative_linguistics|quantitative comparative linguistics or phylogenetics]]), as well as the modeling of changes in sound<ref>Pigoli, Davide, et al. "The analysis of acoustic phonetic data: exploring differences in the spoken romance languages." arXiv preprint arXiv:1507.07587 985 (2015); Group, The Functional Phylogenies. "Phylogenetic inference for function-valued traits: speech sound evolution." Trends in ecology & evolution 27.3 (2012): 160-166..</ref> and meaning.<ref> e.g. Hamilton, William L., Jure Leskovec, and Dan Jurafsky. "Diachronic word embeddings reveal statistical laws of semantic change." arXiv preprint arXiv:1605.09096 (2016).</ref>

==Subfields==
Computational linguistics can be divided into major areas according to different criteria, including:

* '''medium''' of the language being processed, whether spoken or textual: [[speech recognition]] and [[speech synthesis]] deal with how spoken language can be understood or created using computers.
* '''task''' being performed, e.g., whether analyzing language (recognition) or [[natural language generation|synthesizing language (generation)]]: Parsing and generation are sub-divisions of computational linguistics dealing respectively with taking language apart and putting it together. 
* '''intention''': whether it is motivated by real-world applications (applied computational linguistics) or fundamental research (theoretical computational linguistics).

As for the tasks addressed by applied computational linguistics, see [[Natural language processing#Common NLP Tasks|Natural language processing]] article. This includes classical problems such as the design of [[Part-of-speech tagging|POS-taggers (part-of-speech taggers)]], [[parser]]s for [[natural language]]s, or tasks such as [[machine translation]] (MT), the sub-division of computational linguistics dealing with having computers translate between languages. As one of the earliest and most difficult applications of computational linguistics, MT draws on many subfields and both theoretical and applied aspects. Traditionally, automatic language translation has been considered a notoriously hard branch of computational linguistics.<ref>Oettinger, A. G. (1965). [https://www.jstor.org/stable/2313322 Computational Linguistics]. The American Mathematical Monthly, Vol. 72, No. 2, Part 2: Computers and Computing, pp. 147–150.</ref> 

Areas of research that are studied by theoretical computational linguistics include:
*[[Analysis of algorithms|Computational complexity]] of natural language, largely modeled on [[automata theory]], with the application of [[context-sensitive grammar]] and [[Linear bounded automaton|linearly bounded]] [[Turing machine]]s.
*[[Computational semantics]] comprises defining suitable logics for [[linguistic meaning]] representation, automatically constructing them and reasoning with them
Traditionally, applications of computers to address research problems in other branches of linguistics have been described as tasks within computational linguistics. Among other aspects, this includes
* Computer-aided [[corpus linguistics]], which has been used since the 1970s as a way to make detailed advances in the field of discourse analysis<ref name=":2">{{cite book|last=McEnery|first=Thomas|url=https://books.google.com/books?id=nwmgdvN_akAC&q=%22computer+aided+corpus+linguistics%22&pg=PA114|title=Corpus Linguistics: An Introduction|publisher=Edinburgh University Press|year=1996|isbn=978-0748611652|location=Edinburgh|page=114}}</ref>
* Simulation and study of language evolution in [[historical linguistics]]/[[glottochronology]].<ref name=":3" />
== Legacy ==
The subject of computational linguistics has had a recurring impact on popular culture:
* The [[Star Trek]] franchise features heavily classical NLP applications, most notably [[machine translation]] ([[universal translator]]), [[Natural-language user interface|natural language user interfaces]] and [[question answering]].<ref>{{Cite web|title='Star Trek' translators reach for the final frontier|url=http://www.cnn.com/2011/TECH/innovation/01/30/universal.translators.google/index.html|access-date=2020-08-17|website=www.cnn.com|language=en}}</ref>
* The 1983 film ''[[WarGames]]'' features a young computer hacker who interacts with an artificially intelligent supercomputer.<ref>{{Citation|title = WarGames|url = https://www.imdb.com/title/tt0086567/|date = 1983-06-03|access-date = 2016-02-22|first = John|last = Badham}}</ref>
* A 1997 film, ''[[Conceiving Ada]]'', focuses on [[Ada Lovelace]], considered one of the first computer scientists, as well as themes of computational linguistics.<ref>{{Citation|title = Conceiving Ada|url = https://www.imdb.com/title/tt0118882/|date = 1999-02-19|access-date = 2016-02-22|first = Lynn|last = Hershman-Leeson}}</ref>
* ''[[Her (film)|Her]],'' a 2013 film, depicts a man's interactions with the "world's first artificially intelligent operating system."<ref>{{Citation|title = Her|url = https://www.imdb.com/title/tt1798709/|date = 2014-01-10|access-date = 2016-02-18|first = Spike|last = Jonze}}</ref>
* The 2014 film ''[[The Imitation Game]]'' follows the life of computer scientist Alan Turing, developer of the Turing Test.<ref>{{Citation|title = The Imitation Game|url = https://www.imdb.com/title/tt2084970/?ref_=nv_sr_1|date = 2014-12-25|access-date = 2016-02-18|first = Morten|last = Tyldum}}</ref>
* The 2015 film ''[[Ex Machina (film)|Ex Machina]]'' centers around human interaction with artificial intelligence.<ref>{{Citation|title = Ex Machina|url = https://www.imdb.com/title/tt0470752/|date = 2015-04-24|access-date = 2016-02-18|first = Alex|last = Garland}}</ref>
* The 2016 film ''[[Arrival (film)|Arrival]]'', based on [[Ted Chiang]]'s [[Story of Your Life]], takes a whole new approach of linguistics to communicate with advanced alien race called heptapods.<ref>{{cite web |last=Villeneuve |first=Denis |title=Arrival |url=https://www.imdb.com/title/tt2543164/ |date = 2016-10-10 |access-date=18 December 2019}}</ref>

==See also==
{{Portal|Philosophy}}
{{col-begin}}{{!}}style="float: left;"{{!}}
{{col-1-of-3}}
* [[Artificial intelligence in fiction]]
* [[Collostructional analysis]]
* [[Computational lexicology]]
* [[Computational Linguistics (journal)|''Computational Linguistics'' (journal)]]
* [[Computational models of language acquisition]]
* [[Computational semantics]]
* [[Computational semiotics]]
* [[Computer-assisted reviewing]]
{{col-2-of-3}}
* [[Dialog systems]]
* [[Glottochronology]]
* [[Grammar induction]]
* [[Human speechome project]]
* [[Internet linguistics]]
* [[Lexicostatistics]]
* [[Natural language processing]]
{{col-3-of-3}}
* [[Natural language user interface]]
* [[Quantitative linguistics]]
* [[Semantic relatedness]]
* [[Semantometrics]]
* [[Systemic functional linguistics]]
* [[Translation memory]]
* [[Universal Networking Language]]
{{col-end}}

==References==
{{reflist|30em}}

==Further reading==
<!-- In alphabetical order of by last name -->
{{Refbegin}}
* {{cite journal | last1 = Bates | first1 = M | year = 1995 | title = Models of natural language understanding | journal = Proceedings of the National Academy of Sciences of the United States of America | volume = 92 | issue = 22| pages = 9977–9982 | doi=10.1073/pnas.92.22.9977| pmid = 7479812 | pmc = 40721| bibcode = 1995PNAS...92.9977B }}
* Steven Bird, Ewan Klein, and Edward Loper (2009). ''Natural Language Processing with Python''. O'Reilly Media. {{ISBN|978-0-596-51649-9}}.
* Daniel Jurafsky and James H. Martin (2008). ''Speech and Language Processing'', 2nd edition. Pearson Prentice Hall. {{ISBN|978-0-13-187321-6}}.
* Mohamed Zakaria KURDI (2016). ''Natural Language Processing and Computational Linguistics: speech, morphology, and syntax'', Volume 1. ISTE-Wiley. {{ISBN|978-1848218482}}.
* Mohamed Zakaria KURDI (2017). ''Natural Language Processing and Computational Linguistics: semantics, discourse, and applications'', Volume 2. ISTE-Wiley. {{ISBN| 978-1848219212}}.

{{Refend}}

==External links==
{{Wikiversity}}
{{commons category}}
* [http://www.aclweb.org/ Association for Computational Linguistics (ACL)]
** [http://www.aclweb.org/anthology ACL Anthology of research papers]
** [http://aclweb.org/aclwiki/ ACL Wiki for Computational Linguistics]
* [http://www.CICLing.org/ CICLing annual conferences on Computational Linguistics]
* [https://web.archive.org/web/20110122142133/http://www.cla.imcsit.org/ Computational Linguistics&nbsp;– Applications workshop]
* {{webarchive |url=https://web.archive.org/web/20080125103030/http://www.gelbukh.com/clbook/ |date=January 25, 2008 |title=Free online introductory book on Computational Linguistics }}
* [https://web.archive.org/web/20180212202132/http://www.lt-world.org/ Language Technology World]
* [https://web.archive.org/web/20191025033136/http://www.cs.technion.ac.il/~gabr/resources/resources.html Resources for Text, Speech and Language Processing]
* [http://clg.wlv.ac.uk/ The Research Group in Computational Linguistics]

{{Computer science}}

{{Authority control}}

{{DEFAULTSORT:Computational Linguistics}}
[[Category:Computational linguistics| ]]
[[Category:Subfields of computer science]]
[[Category:Formal sciences]]
[[Category:Cognitive science]]
[[Category:Computational fields of study]]